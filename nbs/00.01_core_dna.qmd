---
title: core
jupyter: python3
---


> These functions are designed to be used for working with genetic data.


```{python}
#| '0': d
#| '1': e
#| '2': f
#| '3': a
#| '4': u
#| '5': l
#| '6': t
#| '7': _
#| '8': e
#| '9': x
#| '10': p
#| '11': ' '
#| '12': d
#| '13': 'n'
#| '14': a
```

```{python}
#| '0': h
#| '1': i
#| '2': d
#| '3': e
from nbdev.showdoc import *
```

##  g2fc 
`# originally from nbs/01.04_g2fc_explore_genetic_data.ipynb`

Here I'm adapting an approach I took in `dlgwas` for accessing panzea data to the G2F genotype data release. The table is too big to easily load in an manipulate in pandas so as a work around to easily access specific genomes, I split the table into a separate file for the header and each genome and renamed each so that these files can be read piecemeal. See the Readme below for more details.

```{python}
geno_path = '../data/zma/g2fc/genotypes/'
```

```{python}
from EnvDL.core import print_txt # imports must be in a separate cell https://github.com/fastai/nbdev/blob/master/README.md#q-what-is-the-warning-found-a-cell-containing-mix-of-imports-and-computations-please-use-separate-cells
```

```{python}
print_txt(path = '../data/zma/g2fc/genotypes/'+'split_and_rename.sh')
```

```{python}
import pandas as pd
```

```{python}
# Other than listing the taxa this isn't expected to be of much use for our purposes.
geno_taxa=pd.read_table('../data/zma/g2fc/genotypes/'+'5_Genotype_Data_All_Years_Filter_TaxaSummary.txt')
geno_taxa.head()
```

```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t

def taxa_to_filename(taxa = '05-397/250007467', delim = '/'): return(taxa.replace(delim, '__'))
```

```{python}
(taxa_to_filename(taxa = '05-397/250007467', delim = '/'),
 taxa_to_filename(taxa = '05-397:250007467', delim = ':'))
```


```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t

def exists_geno(
    taxa, # should be the desired taxa or a regex fragment (stopping before the __). E.g. 'B73' or 'B\d+'
    **kwargs # optionally pass in a genome list (this allows for a different path or precomputing if we're finding a lot of genomes)
             # optionally pass in a different path to the snp table folder
    ):
    if 'genome_files_path' not in kwargs.keys():
        genome_files_path = '../data/zma/g2fc/genotypes/snps/'
    else:
        genome_files_path = kwargs['genome_files_path']
    
    if 'genome_files' not in kwargs.keys():
        import os
        genome_files = os.listdir(genome_files_path)
    else:
        genome_files = kwargs['genome_files']
        
    return(True in [True for e in genome_files if e == taxa])
```

```{python}
(exists_geno(taxa = 'W10004_0171__PHZ51'),
 exists_geno(taxa = 'not_real'))
```


```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t
def find_geno(
    taxa, # should be the desired taxa or a regex fragment (stopping before the __). E.g. 'B73' or 'B\d+'
    **kwargs # optionally pass in a genome list (this allows for a different path or precomputing if we're finding a lot of genomes)
             # optionally pass in a different path to the snp table folder
    ):
    "Search for existing marker sets __"
    if 'genome_files_path' not in kwargs.keys():
        genome_files_path = '../data/zma/g2fc/genotypes/snps/'
    else:
        genome_files_path = kwargs['genome_files_path']
    
    if 'genome_files' not in kwargs.keys():
        import os
        genome_files = os.listdir(genome_files_path)
    else:
        genome_files = kwargs['genome_files']
    import re
    return( [e for e in genome_files if re.match(taxa+'__.+', e)] )
```

```{python}
find_geno(taxa = 'W10004_0171')
```

```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t

def get_geno( 
    taxa,
    **kwargs 
    ):
    "Retrieve an existing marker set"
    if 'genome_files_path' not in kwargs.keys():
        genome_files_path = '../data/zma/g2fc/genotypes/snps/'
    else:
        genome_files_path = kwargs['genome_files_path']
        
    with open(genome_files_path+taxa, 'r') as f:
        data = f.read()    
    data = data.split('\t')
    return(data)
```

```{python}
get_geno('W10004_0171__PHZ51')[0:10]
```

In addition to returning a specific taxa, the table's headers can be retieved with "taxa".

```{python}
get_geno(taxa = 'Taxa')[0:4]
```

Converting between site and chromosome/position requires the `AGPv4_site` dataframe. A given record contains the taxa as well as the nucleotides, so with that entry excluded the chromosome / position can be paired up.

```{python}
len(get_geno(taxa = 'Taxa'))
```






```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t

def list_to_ACGT(
    in_seq, # This should be a list with strings corresponding to IUPAC codes e.g. ['A', 'C', 'Y']
    progress = False
):
    import numpy as np
    import tqdm 
    from tqdm import tqdm

    # Convert IUPAC codes into pr ACGT -------------------------------------------
    encode_dict = {
        #     https://www.bioinformatics.org/sms/iupac.html
        #     A     C     G     T
        'A': [1,    0,    0,    0   ],
        'C': [0,    1,    0,    0   ],
        'G': [0,    0,    1,    0   ],
        'T': [0,    0,    0,    1   ],
        'K': [0,    0,    0.5,  0.5 ],
        'M': [0.5,  0.5,  0,    0   ],
        'N': [0.25, 0.25, 0.25, 0.25],
        'R': [0.5,  0,    0.5,  0   ],
        'S': [0,    0.5,  0.5,  0   ],
        'W': [0.5,  0,    0,    0.5 ],
        'Y': [0,    0.5,  0,    0.5 ],
        #     Other values (assumed empty)
        #     A     C     G     T
         '': [0,    0,    0,    0   ],
        '-': [0,    0,    0,    0   ],
        '0': [0,    0,    0,    0   ],
    }


    # Cleanup -- 
    # Any newlines need to be removed
    in_seq = [e.replace('\n', '') for e in in_seq]

    # Check if there's anything that should be in the dictionary but is not.
    not_in_dict = [e for e in list(set(in_seq)) if e not in list(encode_dict.keys())]

    if not_in_dict != []:
        print("Waring: The following are not in the encoding dictionary and will be set as missing.\n"+str(not_in_dict))

    in_seq = [e if e not in not_in_dict else '' for e in in_seq] 

    # output matrix
    GMat = np.zeros(shape = [len(in_seq), 4])

    # convert all nucleotides to probabilities
    if progress == True:
        for nucleotide in tqdm(encode_dict.keys()):
            mask = [True if e == nucleotide else False for e in  in_seq]
            GMat[mask, :] = encode_dict[nucleotide]    
    else:
        for nucleotide in encode_dict.keys():
            mask = [True if e == nucleotide else False for e in  in_seq]
            GMat[mask, :] = encode_dict[nucleotide]

    return(GMat)
```

```{python}
list_to_ACGT(in_seq = get_geno('W10004_0171__PHZ51')[1:] )[0:10]
```

```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t

def calc_needed_hilbert_p(n_needed = 1048576,
                          max_p = 20):
    out = None
    for i in range(1, max_p):
        if 4**i > n_needed:
            out = i
            break
    return(out)
```

```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t

def np_2d_to_hilbert(
    in_seq, # This should be a 2d numpy array with dimensions of [sequence, channels] 
    **kwargs # for silent
):
    import numpy as np
    import tqdm
    from tqdm import tqdm
    
    import hilbertcurve
    from hilbertcurve.hilbertcurve import HilbertCurve
    
    import EnvDL
    from EnvDL.dna import calc_needed_hilbert_p
    
    n_snps = in_seq.shape[0]
    n_channels = in_seq.shape[-1]
    temp = in_seq

    p_needed = calc_needed_hilbert_p(n_needed=n_snps)
    
    # Data represented need not be continuous -- it need only have int positions
    # a sequence or a sequence with gaps can be encoded
    hilbert_curve = HilbertCurve(
        p = p_needed, # iterations i.e. hold 4^p positions
        n = 2    # dimensions
        )

    points = hilbert_curve.points_from_distances(range(n_snps))

    dim_0 = np.max(np.array(points)[:, 0])+1 # add 1 to account for 0 indexing
    dim_1 = np.max(np.array(points)[:, 1])+1
    temp_mat = np.zeros(shape = [dim_0, dim_1, n_channels])
    temp_mat[temp_mat == 0] = np.nan         #  empty values being used for visualization

    if "silent" in kwargs:
        for i in range(n_snps):
            temp_mat[points[i][0], points[i][1], :] = temp[i]
    else:
        for i in tqdm(range(n_snps)):
            temp_mat[points[i][0], points[i][1], :] = temp[i]

    return(temp_mat)
```

```{python}
#| '0': e
#| '1': x
#| '2': p
#| '3': o
#| '4': r
#| '5': t
def np_3d_to_hilbert(
    in_seq, # This should be a 3d numpy array with dimensions of [samples, sequence, channels] 
    **kwargs
):
    "This is the 3d version of `np_2d_to_hilbert`. The goal is to process all of the samples of an array in one go."
    import numpy as np
    import tqdm
    from tqdm import tqdm
    
    import hilbertcurve
    from hilbertcurve.hilbertcurve import HilbertCurve

    import EnvDL
    from EnvDL.dna import calc_needed_hilbert_p
    
    n_snps = in_seq.shape[1]
    n_channels = in_seq.shape[-1]
    temp = in_seq

    p_needed = calc_needed_hilbert_p(n_needed=n_snps)
    
    # Data represented need not be continuous -- it need only have int positions
    # a sequence or a sequence with gaps can be encoded
    hilbert_curve = HilbertCurve(
        p = p_needed, # iterations i.e. hold 4^p positions
        n = 2    # dimensions
        )

    points = hilbert_curve.points_from_distances(range(n_snps))

    dim_0 = np.max(np.array(points)[:, 0])+1 # add 1 to account for 0 indexing
    dim_1 = np.max(np.array(points)[:, 1])+1
    temp_mat = np.zeros(shape = [in_seq.shape[0], dim_0, dim_1, n_channels])
    temp_mat[temp_mat == 0] = np.nan         #  empty values being used for visualization
    
    if "silent" in kwargs:
        for i in range(n_snps):
            temp_mat[:,                          # sample
                     points[i][0], points[i][1], # x, y
                     :] = temp[:, i]             # channels
    else:
        for i in tqdm(range(n_snps)):
            temp_mat[:,                          # sample
                     points[i][0], points[i][1], # x, y
                     :] = temp[:, i]             # channels

    return(temp_mat)
```

```{python}
import numpy as np
import plotly.express as px
```

```{python}
demo = np_2d_to_hilbert(
    in_seq = np.asarray([np.linspace(1, 100, num= 50),
                         np.linspace(100, 1, num= 50)]).T
)

px.imshow(demo[:,:,0])
```

```{python}
px.imshow(demo[:,:,1])
```

## Apply to subset of real marker data

Explictly convert a taxa

```{python}
taxa_to_filename(taxa = 'W10004_0171/PHZ51')
```

Or search for a taxa

```{python}
find_geno(taxa = 'W10004_0171')
```

Retrieve the sequence data

```{python}
res = get_geno(taxa_to_filename(taxa = 'W10004_0171/PHZ51')) 
res = res[1:] # drop taxa
res[0:10]
```

Convert from characters to encoded nucleotide probabilities

```{python}
res = list_to_ACGT(in_seq = res)
res = res[0:1000]
res
```

Convert the sequence to a hilbert curve

```{python}
# This will happen under the hood
# calc_needed_hilbert_p(n_needed=res.shape[0])
res_hilb = np_2d_to_hilbert(
    in_seq = res
)
```

```{python}
px.imshow( res[0:20, 0:1] )
```

```{python}
px.imshow( res_hilb[:, :, 0] )
```

```{python}
px.imshow( res_hilb[:, :, 1] )
```

```{python}
#| '0': h
#| '1': i
#| '2': d
#| '3': e
import nbdev; nbdev.nbdev_export()
```


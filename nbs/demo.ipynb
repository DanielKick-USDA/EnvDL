{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aadccc0",
   "metadata": {},
   "source": [
    "# Demo Model\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F # F.mse_loss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_obs = 100 \n",
    "# n_degree = 5\n",
    "\n",
    "\n",
    "# n_poly = n_degree + 1\n",
    "# # X = torch.randn(n_obs).reshape((n_obs, 1))\n",
    "# X = torch.linspace(-10, 10, n_obs).reshape((n_obs, 1))\n",
    "# coefs_poly = torch.randn((n_poly))\n",
    "# # coefs_poly = coefs_poly/torch.linspace(1, n_poly, n_poly)\n",
    "# y = (coefs_poly * (X**torch.tensor([i for i in range(n_poly)]))).sum(axis = 1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afad1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_obs = 1001\n",
    "bounds = (-4, 4)\n",
    "X = torch.linspace(bounds[0], bounds[1], sim_obs).reshape((sim_obs, 1))[:, 0]\n",
    "y = torch.Tensor(\n",
    "    0.01*(\n",
    "        X**6 - \n",
    "      2*X**5 - \n",
    "     26*X**4 + \n",
    "     28*X**3 + \n",
    "    145*X**2 - \n",
    "     26*X    - \n",
    "     80)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds(Dataset):\n",
    "    def __init__(self, y, X): \n",
    "        self.y = y\n",
    "        self.X = X\n",
    "    def __len__(self): \n",
    "        return(len(self.y))\n",
    "    def __getitem__(self, index):\n",
    "        return self.y[index], self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x = torch.Tensor(X).numpy(), \n",
    "           y = torch.Tensor(y).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cdfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame({\n",
    "    'F(x)':0.5*X**2,\n",
    "    'x':X})\n",
    "tmp['x1.Linear']= [e for e in tmp['x']]\n",
    "tmp['x1.NonLinear']= [e if e >0 else 0 for e in tmp['x1.Linear']]\n",
    "\n",
    "tmp['x2.Linear']= [-2*e for e in tmp['x']]\n",
    "tmp['x2.NonLinear']= [e if e >0 else 0 for e in tmp['x2.Linear']]\n",
    "\n",
    "tmp['yhat.Linear']= tmp['x1.Linear']+tmp['x2.Linear']\n",
    "tmp['yhat.NonLinear']= tmp['x1.NonLinear']+tmp['x2.NonLinear']\n",
    "px.scatter(tmp.melt('x', value_name='output'), x='x', y='output', facet_col='variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 50\n",
    "\n",
    "even_idxs = torch.linspace(0, X.shape[0]-1, n_obs).int()\n",
    "\n",
    "clustered_idxs = (torch.randn(n_obs)*100) + sim_obs//2 # center b/c these will become indices\n",
    "clustered_idxs = clustered_idxs.int()\n",
    "# clamp to min /max\n",
    "clustered_idxs[(clustered_idxs < 0)] = 0\n",
    "clustered_idxs[(clustered_idxs >= sim_obs)] = sim_obs-1\n",
    "\n",
    "# px.histogram(x = clustered_idxs, nbins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2080f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "df = pd.DataFrame(torch.concat([torch.Tensor(X)[:, None], torch.Tensor(y)[:, None]], axis = 1).numpy(), columns=['x', 'y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86485bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    pd.concat([\n",
    "        df.assign(Sample = 'All'),\n",
    "        df.loc[even_idxs].assign(Sample = 'Unbiased'),\n",
    "        df.loc[clustered_idxs].assign(Sample = 'Biased')\n",
    "        ]),\n",
    "    x = 'x', y='y', color = 'Sample'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233125f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[even_idxs, None]\n",
    "\n",
    "# even_idxs = [int(e) for e in even_idxs]\n",
    "\n",
    "# X[even_idxs, None]\n",
    "\n",
    "# even_idxs = [int(e) for e in range(50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "training_dataloader_even = DataLoader(\n",
    "    ds(y = y[even_idxs, None], \n",
    "       X = X[even_idxs, None]),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "\n",
    "training_dataloader_uneven = DataLoader(\n",
    "    ds(y = y[clustered_idxs, None], \n",
    "       X = X[clustered_idxs, None]),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    ds(y = y[:, None], \n",
    "       X = X[:, None]),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4ff3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e348a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, inp_size = 1, out_size = 1, hidden_layers = []):\n",
    "        super(NeuralNetwork, self).__init__()    \n",
    "\n",
    "        hidden_layers = [inp_size]+hidden_layers+[out_size]   \n",
    "        print(hidden_layers)     \n",
    "        layer_list = []\n",
    "        for i in range(len(hidden_layers)):\n",
    "            if i+2 > len(hidden_layers):\n",
    "                pass\n",
    "            elif i+2 < len(hidden_layers):\n",
    "                layer_list += [nn.Linear(hidden_layers[i], hidden_layers[i+1]), \n",
    "                               nn.ReLU()]\n",
    "            else:\n",
    "                layer_list += [nn.Linear(hidden_layers[i], hidden_layers[i+1])]\n",
    "        self.x_network = nn.ModuleList(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.x_network:\n",
    "            x = m(x)\n",
    "        return x\n",
    "    \n",
    "model = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [])\n",
    "# model( next(iter(training_dataloader_even))[1][:, None] )[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cebec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ModelHelper():\n",
    "    def __init__(self, model, ds_train, ds_valid) -> None:\n",
    "        self.ds_train = ds_train \n",
    "        self.ds_valid = ds_valid\n",
    "\n",
    "        self.model = model\n",
    "        # self.optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)        \n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr= 1e-2)        \n",
    "        self.loss_fn = F.mse_loss\n",
    "    \n",
    "        self.epoch = 0\n",
    "        self.history = {\n",
    "            'train': {'epoch':[], 'loss':[]},\n",
    "            'valid': {'epoch':[], 'loss':[]}\n",
    "        }\n",
    "\n",
    "        self.yhats = {\n",
    "            'valid': {'epoch':[], 'yhat':[]}\n",
    "        }\n",
    "\n",
    "    def _epoch_optim(self, dataloader):\n",
    "        for batch, (y_i, xs_i) in enumerate(dataloader):\n",
    "            pred = self.model(xs_i)\n",
    "            loss = self.loss_fn(pred, y_i)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def _calc_ds_loss(self, dataloader):\n",
    "        with torch.no_grad():\n",
    "            loss_tally = []\n",
    "            obs_tally = []\n",
    "            for batch, (y_i, xs_i) in enumerate(dataloader):\n",
    "                pred = self.model(xs_i)\n",
    "                loss = self.loss_fn(pred, y_i)   \n",
    "                loss_tally+= [loss[None]]\n",
    "                obs_tally += [len(y_i)]\n",
    "\n",
    "            obs_tally = torch.tensor(obs_tally)\n",
    "            # calculate average of batch mse weighted by batch size (in case of inequal batch sizes)\n",
    "            return float(sum(torch.concat(loss_tally, axis = 0)*(obs_tally/sum(obs_tally))))\n",
    "    \n",
    "    def _calc_yhats(self, dataloader):\n",
    "        with torch.no_grad():\n",
    "            yhats = []\n",
    "            for batch, (y_i, xs_i) in enumerate(dataloader):\n",
    "                yhats += [self.model(xs_i)]\n",
    "            return torch.concat(yhats)\n",
    "\n",
    "    def log_loss(self):\n",
    "        self.history['train']['epoch'] += [self.epoch]\n",
    "        self.history['valid']['epoch'] += [self.epoch]\n",
    "        self.history['train']['loss']  += [self._calc_ds_loss(dataloader=self.ds_train)]\n",
    "        self.history['valid']['loss']  += [self._calc_ds_loss(dataloader=self.ds_valid)]\n",
    "\n",
    "    def log_yhats(self):\n",
    "        self.yhats['valid']['epoch'] += [self.epoch]\n",
    "        self.yhats['valid']['yhat']  += [self._calc_yhats(dataloader=self.ds_valid)]\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.epoch += 1\n",
    "        self._epoch_optim(dataloader = self.ds_train)\n",
    "        \n",
    "\n",
    "    def train(self, epochs = 1, save_yhat_every = 1):\n",
    "        self.log_yhats()\n",
    "        for i in tqdm(range(epochs)):\n",
    "            self.train_epoch()\n",
    "            self.log_loss()\n",
    "            if self.epoch % save_yhat_every == 0:\n",
    "                self.log_yhats()\n",
    "\n",
    "    def tidy_history(self):\n",
    "        history = pd.concat([\n",
    "            pd.DataFrame(self.history['train']).assign(split = 'train'),\n",
    "            pd.DataFrame(self.history['valid']).assign(split = 'valid')])\n",
    "        return history\n",
    "\n",
    "    def tidy_history_yhats(self):        \n",
    "        res_list = []\n",
    "        \n",
    "        epochs_run = len(self.yhats['valid']['epoch'])\n",
    "        for i in range(epochs_run):\n",
    "            vals = self.yhats['valid']['yhat'][i]\n",
    "            res_list += [torch.concat([\n",
    "                vals, \n",
    "                torch.tensor(\n",
    "                    self.yhats['valid']['epoch'][i]\n",
    "                    ).repeat(vals.shape[0])[:, None]], \n",
    "                    axis = 1\n",
    "            )]\n",
    "        yhat_df = pd.DataFrame(torch.concat(res_list).numpy(), columns=['yhat', 'epoch'])\n",
    "        x_df = pd.DataFrame(torch.concat([xs_i for batch, (_, xs_i) in enumerate(self.ds_valid)]).repeat([epochs_run, 1]).numpy(), columns = ['x'])\n",
    "        yhat_df = pd.concat([yhat_df, x_df], axis = 1)\n",
    "        yhat_df.epoch = yhat_df.epoch.astype(int)\n",
    "        return yhat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = ModelHelper(model = NeuralNetwork(),\n",
    "                 ds_train = training_dataloader_even, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=100, save_yhat_every = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b34449",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(mh.tidy_history(), x = 'epoch', y = 'loss', color = 'split')\n",
    "# mh.tidy_history_yhats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = mh.tidy_history_yhats()\n",
    "\n",
    "def _add_ref_to_yhats(tmp, y, X):\n",
    "    ref = pd.DataFrame(\n",
    "        torch.concat([\n",
    "            torch.concat([\n",
    "                torch.Tensor(y)[:, None], \n",
    "                torch.Tensor(X)[:, None]], \n",
    "                axis = 1).repeat([len(list(set(tmp.epoch))), 1]), \n",
    "                \n",
    "                torch.tensor(tmp.epoch)[:, None]\n",
    "                ], axis = 1\n",
    "        ).numpy(), \n",
    "                columns=['yhat', 'x', 'epoch'])\n",
    "\n",
    "    ref.epoch = ref.epoch.astype(int)\n",
    "    ref['type'] = 'F(x)'\n",
    "    tmp['type'] = 'Predicted'\n",
    "    tmp = pd.concat([ref.loc[(ref.epoch.isin(list(set(tmp.epoch)))), ], tmp], axis = 0 )\n",
    "    return(tmp)\n",
    "\n",
    "# fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch')\n",
    "# # # https://community.plotly.com/t/how-to-slow-down-animation-in-plotly-express/31309/5\n",
    "# fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 0.1\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00bfefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_even, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=100, save_yhat_every = 5)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Linear Model')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f76d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [1])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_even, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=500, save_yhat_every = 10)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Hidden Units: 1')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03967a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [16])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_even, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=500, save_yhat_every = 10)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Hidden Units: 16')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [16,16])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_even, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=500, save_yhat_every = 10)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Hidden Units: 16, 16')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens as we increase capacity? Depth?\n",
    "n_layers = 1\n",
    "n_units =1\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for n_layers in [i for i in range(1, 2)]:\n",
    "    for n_units in [i for i in [1]+[10*e for e in range(1, 21)]]:\n",
    "        nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [n_units for i in range(n_layers)])\n",
    "        mh = ModelHelper(model = nnet,\n",
    "                        ds_train = training_dataloader_even, \n",
    "                        ds_valid = valid_dataloader)\n",
    "\n",
    "        mh.log_loss()\n",
    "        mh.train(epochs=500, save_yhat_every = 500)\n",
    "        temp = _add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X)\n",
    "\n",
    "        temp['layers']=n_layers\n",
    "        temp['units']=n_units\n",
    "\n",
    "        temp_list += [temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac77e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.concat(temp_list)\n",
    "tmp=tmp.loc[tmp.epoch==500,]\n",
    "\n",
    "fig = px.scatter(tmp, x = 'x', y = 'yhat', color = 'type', animation_frame='units', title='Increasing Units 1 -> 200')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 4\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dcbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "\n",
    "for n_layers in [i for i in range(1, 21, 1)]:\n",
    "    for n_units in [i for i in [10]]:\n",
    "        nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [n_units for i in range(n_layers)])\n",
    "        mh = ModelHelper(model = nnet,\n",
    "                        ds_train = training_dataloader_even, \n",
    "                        ds_valid = valid_dataloader)\n",
    "\n",
    "        mh.log_loss()\n",
    "        mh.train(epochs=500, save_yhat_every = 500)\n",
    "        temp = _add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X)\n",
    "\n",
    "        temp['layers']=n_layers\n",
    "        temp['units']=n_units\n",
    "\n",
    "        temp_list += [temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.concat(temp_list)\n",
    "tmp=tmp.loc[tmp.epoch==500,]\n",
    "\n",
    "fig = px.scatter(tmp, x = 'x', y = 'yhat', color = 'type', animation_frame='layers', title='Increasing layers 1 -> 20')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 250\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(tmp, x = 'x', y = 'yhat', color = 'type', facet_col='layers', title='Increasing layers 1 -> 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3625ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a269a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67842b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [256, 256, 256, 256])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_even, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=500, save_yhat_every = 25)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Unbiased Sampling')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [256, 256, 256, 256])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_uneven, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=500, save_yhat_every = 25)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Biased Sampling')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(mh.tidy_history(), x = 'epoch', y = 'loss', color = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNetwork(inp_size = 1, out_size = 1, hidden_layers = [])\n",
    "mh = ModelHelper(model = nnet,\n",
    "                 ds_train = training_dataloader_uneven, \n",
    "                 ds_valid = valid_dataloader)\n",
    "\n",
    "mh.log_loss()\n",
    "mh.train(epochs=500, save_yhat_every = 25)\n",
    "\n",
    "fig = px.scatter(_add_ref_to_yhats(mh.tidy_history_yhats(), y = y, X= X), x = 'x', y = 'yhat', color = 'type', animation_frame='epoch', title='Biased Sampling')\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(mh.tidy_history(), x = 'epoch', y = 'loss', color = 'split')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

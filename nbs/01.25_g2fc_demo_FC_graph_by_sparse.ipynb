{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aadccc0",
   "metadata": {},
   "source": [
    "# Demonstrate building a FC network with arbitrary graph structure _using sparse matrices_. \n",
    "\n",
    "> This aims to create VNNs far more quickly and easily than the existing means. The key problem is that the existing VNN code is _slow_ to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ee9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from EnvDL.core import ensure_dir_path_exists \n",
    "from EnvDL.dlfn import g2fc_datawrapper, BigDataset, plDNN_general\n",
    "from EnvDL.dlfn import ResNet2d, BasicBlock2d\n",
    "from EnvDL.dlfn import LSUV_\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F # F.mse_loss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from EnvDL.dlfn import kegg_connections_build, kegg_connections_clean, kegg_connections_append_y_hat, kegg_connections_sanitize_names\n",
    "from EnvDL.dlfn import VNNHelper, VisableNeuralNetwork, Linear_block_reps\n",
    "from EnvDL.dlfn import plDNN_general, BigDataset\n",
    "from EnvDL.dlfn import reverse_edge_dict, reverse_node_props\n",
    "from EnvDL.dlfn import VNNVAEHelper, plVNNVAE\n",
    "from EnvDL.dlfn import kegg_connections_build, kegg_connections_clean, kegg_connections_append_y_hat, kegg_connections_sanitize_names\n",
    "from EnvDL.dlfn import VNNHelper, VisableNeuralNetwork, Linear_block_reps\n",
    "from EnvDL.dlfn import ListDataset, plVNN\n",
    "from EnvDL.dlfn import plDNN_general, BigDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f431ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62b0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b078cad8",
   "metadata": {},
   "source": [
    "The workhorse of this approach is a customized version of `sparselinear.SparseLinear`. The key extension here is to allow for custom weights and biases to be passed in. This allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d04993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_sparse \n",
    "\n",
    "# extending SparseLinear layer to allow for custom weights and biases to be passed in. \n",
    "class SparseLinearCustom(nn.Module):\n",
    "    \"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "    \n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        sparsity: sparsity of weight matrix\n",
    "            Default: 0.9\n",
    "        connectivity: user defined sparsity matrix\n",
    "            Default: None\n",
    "        small_world: boolean flag to generate small world sparsity\n",
    "            Default: ``False``\n",
    "        dynamic: boolean flag to dynamically change the network structure\n",
    "            Default: ``False``\n",
    "        deltaT (int): frequency for growing and pruning update step\n",
    "            Default: 6000\n",
    "        Tend (int): stopping time for growing and pruning algorithm update step\n",
    "            Default: 150000\n",
    "        alpha (float): f-decay parameter for cosine updates\n",
    "            Default: 0.1\n",
    "        max_size (int): maximum number of entries allowed before chunking occurrs\n",
    "            Default: 1e8\n",
    "    \n",
    "    Shape:\n",
    "        - Input: :math:`(N, *, H_{in})` where :math:`*` means any number of\n",
    "          additional dimensions and :math:`H_{in} = \\text{in\\_features}`\n",
    "        - Output: :math:`(N, *, H_{out})` where all but the last dimension\n",
    "          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
    "    \n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "    \n",
    "    Examples::\n",
    "        \n",
    "        >>> m = nn.SparseLinear(20, 30)\n",
    "        >>> input = torch.randn(128, 20)\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([128, 30])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, sparsity=0.9, connectivity=None, small_world=False, dynamic=False, deltaT=6000, Tend=150000, alpha=0.1, max_size=1e8,\n",
    "                 custom_weights=None, custom_bias=None, \n",
    "                 weight_grad_bool=None, bias_grad_bool=None # indices in sparse format for those entries that should have their gradients NOT zeroed (non identity cells)\n",
    "                 ):\n",
    "        assert in_features < 2**31 and out_features < 2**31 and sparsity < 1.0\n",
    "        assert connectivity is None or not small_world, \"Cannot specify connectivity along with small world sparsity\"\n",
    "        if connectivity is not None:\n",
    "            assert isinstance(connectivity, torch.LongTensor) or isinstance(connectivity, torch.cuda.LongTensor), \"Connectivity must be a Long Tensor\"\n",
    "            assert connectivity.shape[0]==2 and connectivity.shape[1]>0, \"Input shape for connectivity should be (2,nnz)\"\n",
    "            assert connectivity.shape[1] <= in_features*out_features, \"Nnz can't be bigger than the weight matrix\"\n",
    "        super(SparseLinearCustom, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.connectivity = connectivity\n",
    "        self.small_world = small_world\n",
    "        self.dynamic = dynamic\n",
    "        self.max_size = max_size\n",
    "\n",
    "\n",
    "        self.weight_grad_bool = None\n",
    "        self.bias_grad_bool   = None\n",
    "        if weight_grad_bool != None:\n",
    "            self.weight_grad_bool = nn.Parameter(weight_grad_bool).requires_grad_(False)\n",
    "\n",
    "        if bias_grad_bool != None:\n",
    "            self.bias_grad_bool    = nn.Parameter(bias_grad_bool).requires_grad_(False)\n",
    "        \n",
    "        # Generate and coalesce indices\n",
    "        coalesce_device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # Faster to coalesce on GPU\n",
    "        if not small_world:\n",
    "            if connectivity is None:\n",
    "                self.sparsity = sparsity\n",
    "                nnz = round((1.0-sparsity) * in_features * out_features)\n",
    "                if in_features * out_features <= 10**8:\n",
    "                    indices = np.random.choice(in_features * out_features, nnz, replace=False)\n",
    "                    indices = torch.as_tensor(indices, device=coalesce_device)\n",
    "                    row_ind = indices.floor_divide(in_features)\n",
    "                    col_ind = indices.fmod(in_features)\n",
    "                else:\n",
    "                    warnings.warn(\"Matrix too large to sample non-zero indices without replacement, sparsity will be approximate\", RuntimeWarning)\n",
    "                    row_ind = torch.randint(0, out_features, (nnz,), device=coalesce_device)\n",
    "                    col_ind = torch.randint(0, in_features, (nnz,), device=coalesce_device)\n",
    "                indices = torch.stack((row_ind, col_ind))\n",
    "            else:\n",
    "                # User defined sparsity\n",
    "                nnz = connectivity.shape[1]\n",
    "                self.sparsity = nnz/(out_features*in_features)\n",
    "                connectivity = connectivity.to(device=coalesce_device)\n",
    "                indices = connectivity\n",
    "                \n",
    "        else:\n",
    "            #Generate small world sparsity\n",
    "            self.sparsity = sparsity\n",
    "            nnz = round((1.0-sparsity) * in_features * out_features)\n",
    "            assert nnz > min(in_features, out_features), 'The matrix is too sparse for small-world algorithm; please decrease sparsity'\n",
    "            offset = abs(out_features - in_features) / 2.\n",
    "\n",
    "            # Node labels\n",
    "            inputs = torch.arange(1 + offset * (out_features > in_features), in_features + 1 + offset * (out_features > in_features), device=coalesce_device)\n",
    "            outputs = torch.arange(1 + offset * (out_features < in_features), out_features + 1 + offset * (out_features < in_features), device=coalesce_device)\n",
    "\n",
    "            total_data = in_features * out_features                 # Total params\n",
    "            chunks = math.ceil(total_data / self.max_size)\n",
    "            split_div = max(in_features, out_features) // chunks    # Full chunks\n",
    "            split_mod = max(in_features, out_features) % chunks     # Remaining chunk\n",
    "            idx = torch.repeat_interleave(torch.Tensor([split_div]), chunks).int().to(device=coalesce_device)\n",
    "            idx[:split_mod] += 1\n",
    "            idx = torch.cumsum(idx, dim=0)\n",
    "            idx = torch.cat([torch.LongTensor([0]).to(device=coalesce_device), idx])\n",
    "\n",
    "            count = 0\n",
    "\n",
    "            rows = torch.empty(0).long().to(device=coalesce_device)\n",
    "            cols = torch.empty(0).long().to(device=coalesce_device)\n",
    "\n",
    "            def small_world_chunker(inputs, outputs, nnz):\n",
    "                pair_distance = inputs.view(-1, 1) - outputs\n",
    "                arg = torch.abs(pair_distance) + 1.\n",
    "                # lambda search\n",
    "                error = float('inf')\n",
    "                L, U = 1e-5, 5.  \n",
    "                lamb = 1.                   # initial guess\n",
    "                itr = 1\n",
    "                error_threshold = 10.\n",
    "                max_itr = 1000\n",
    "                P = arg**(-lamb)\n",
    "                P_sum = P.sum()\n",
    "                error = abs(P_sum - nnz)\n",
    "\n",
    "                while error > error_threshold:\n",
    "                    assert itr <= max_itr, 'No solution found; please try different network sizes and sparsity levels'\n",
    "                    if P_sum < nnz:\n",
    "                        U = lamb\n",
    "                        lamb = (lamb + L) / 2.\n",
    "                    elif P_sum > nnz:\n",
    "                        L = lamb\n",
    "                        lamb = (lamb + U) / 2.\n",
    "                        \n",
    "                    P = arg**(-lamb)\n",
    "                    P_sum = P.sum()\n",
    "                    error = abs(P_sum - nnz)\n",
    "                    itr += 1\n",
    "                return P\n",
    "\n",
    "            for i in range(chunks):\n",
    "                inputs_ = inputs[idx[i]:idx[i+1]] if out_features <= in_features else inputs\n",
    "                outputs_ = outputs[idx[i]:idx[i+1]] if out_features > in_features else outputs\n",
    "\n",
    "                y = small_world_chunker(inputs_, outputs_, round(nnz / chunks))\n",
    "                ref = torch.rand_like(y)\n",
    "                \n",
    "                mask = torch.empty(y.shape, dtype=bool).to(device=coalesce_device)\n",
    "                mask[y < ref] = False\n",
    "                mask[y >= ref] = True\n",
    "\n",
    "                rows_, cols_ = mask.to_sparse().indices()\n",
    "\n",
    "                rows = torch.cat([rows, rows_ + idx[i]])\n",
    "                cols = torch.cat([cols, cols_])\n",
    "\n",
    "            indices = torch.stack((cols, rows))\n",
    "            nnz = indices.shape[1]\n",
    "\n",
    "        # Extending this code to allow for values to be passed in.\n",
    "        if custom_weights == None:\n",
    "            values = torch.empty(nnz, device=coalesce_device)\n",
    "        else:\n",
    "            # print('ding')\n",
    "            values = custom_weights.to(coalesce_device)\n",
    "            # print(values)\n",
    "        indices, values = torch_sparse.coalesce(indices, values, out_features, in_features)\n",
    "        # print(values)\n",
    "        \n",
    "        self.register_buffer('indices', indices.cpu())\n",
    "        self.weights = nn.Parameter(values.cpu())\n",
    "        # print(self.weights)\n",
    "\n",
    "\n",
    "        if bias:\n",
    "            # also extending bias to allow for custom bias vector\n",
    "            if custom_bias == None:\n",
    "                self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(custom_bias)\n",
    "            \n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        if self.dynamic:\n",
    "            self.deltaT = deltaT\n",
    "            self.Tend = Tend\n",
    "            self.alpha = alpha\n",
    "            self.itr_count = 0\n",
    "\n",
    "        custom_weights_bool = True if custom_weights is not None else False\n",
    "        custom_bias_bool    = True if custom_bias    is not None else False\n",
    "\n",
    "        self.reset_parameters(custom_weights_bool=custom_weights_bool, \n",
    "                              custom_bias_bool= custom_bias_bool)\n",
    "\n",
    "    def reset_parameters(self, custom_weights_bool, custom_bias_bool):\n",
    "        # only do if parameters were not manually set:\n",
    "        bound = 1 / self.in_features**0.5\n",
    "        if custom_weights_bool:\n",
    "            pass\n",
    "        else:\n",
    "            nn.init.uniform_(self.weights, -bound, bound)\n",
    "        if custom_bias_bool:\n",
    "            pass\n",
    "        elif self.bias is not None:\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        \"\"\" returns a torch.sparse.FloatTensor view of the underlying weight matrix \n",
    "            This is only for inspection purposes and should not be modified or used in any autograd operations\n",
    "        \"\"\"\n",
    "        weight = torch.sparse.FloatTensor(self.indices, self.weights, (self.out_features, self.in_features))\n",
    "        return weight.coalesce().detach()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.dynamic:\n",
    "            self.itr_count+= 1\n",
    "        output_shape = list(inputs.shape)\n",
    "        output_shape[-1] = self.out_features\n",
    "\n",
    "        # Handle dynamic sparsity\n",
    "        if self.training and self.dynamic and self.itr_count < self.Tend and self.itr_count%self.deltaT==0:\n",
    "            \n",
    "            #Drop criterion\n",
    "            f_decay = self.alpha * (1 + math.cos(self.itr_count * math.pi/self.Tend))/2\n",
    "            k = int(f_decay *( 1 - self.sparsity ) * self.weights.view(-1,1).shape[0])\n",
    "            n = self.weights.shape[0]\n",
    "            \n",
    "            _, lm_indices = torch.topk(-torch.abs(self.weights),n-k, largest=False, sorted=False)\n",
    "\n",
    "            self.indices = torch.index_select(self.indices,1, lm_indices)\n",
    "            self.weights = nn.Parameter(torch.index_select(self.weights, 0, lm_indices))\n",
    "\n",
    "            device = inputs.device\n",
    "            #Growth criterion\n",
    "            self.weights = nn.Parameter(torch.cat((self.weights,((torch.zeros(k))).to(device=device)),dim=0))\n",
    "            self.indices = torch.cat((self.indices,torch.zeros((2,k), dtype=torch.long).to(device=device)),dim=1)\n",
    "            output = GrowConnections.apply( inputs, self.weights, k, self.indices, (self.out_features, self.in_features), self.max_size)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if len(output_shape) == 1: inputs = inputs.view(1, -1)\n",
    "            inputs = inputs.flatten(end_dim=-2)\n",
    "\n",
    "            output = torch_sparse.spmm(self.indices, self.weights, self.out_features, self.in_features, inputs.t()).t()\n",
    "            if self.bias is not None:\n",
    "                output += self.bias\n",
    " \n",
    "        return output.view(output_shape)\n",
    "            \n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, sparsity={}, connectivity={}, small_world={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.sparsity, self.connectivity, self.small_world\n",
    "        )\n",
    "\n",
    "# prepare to add in dropout\n",
    "# model = SparseLinearCustom(4, 4, \n",
    "#                    connectivity=torch.LongTensor(torch.eye(4).to_sparse().indices()),\n",
    "#                    custom_weights=torch.eye(4).to_sparse().values(), \n",
    "#                    custom_bias=torch.tensor([0., 0, 0, 0]))\n",
    "# model((torch.ones(4)+1))\n",
    "\n",
    "# pr = 0.9\n",
    "# torch.bernoulli(torch.tensor(pr).repeat(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# # \n",
    "    #\n",
    "      #\n",
    "\n",
    "SparseLinearCustom(\n",
    "    4, 4,\n",
    "    connectivity   = torch.LongTensor(torch.tensor([[0, 0, 1, 1, 2, 3],\n",
    "                                                    [0, 1, 0, 1, 2, 3]])),\n",
    "    custom_weights = torch.tensor([-0.2665,  0.3926, -0.2531,  0.3266,  1.0000, 1.0000]), \n",
    "    custom_bias    = torch.tensor([-0.2665,  0.3926, -0.2531,  0.3266,  1.0000, 1.0000])\n",
    ").weight.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sparselinear import SparseLinear\n",
    "   \n",
    "model = SparseLinearCustom(4, 4, \n",
    "                   connectivity=torch.LongTensor(torch.eye(4).to_sparse().indices()),\n",
    "                   custom_weights=torch.eye(4).to_sparse().values(), \n",
    "                   custom_bias=torch.tensor([0., 0, 0, 0]))\n",
    "\n",
    "model.weight.to_dense(), model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2e397",
   "metadata": {},
   "source": [
    "The core idea here is that if we have some graph\n",
    "\n",
    "```\n",
    "A -> C\n",
    "       \\\n",
    "B -> D -> E\n",
    " \\     /\n",
    "  ----- \n",
    "```\n",
    "\n",
    "Let's suppose that each of these nodes is a dense neural network layer. The first two (A,B) nodes are input nodes. To keep everything simple we'll have all nodes produce one output value. Originally we represented this as a graph of networks and stored the outputs of each node. This is a conveninet way to represent this model but results in a _lot_ of stored outputs and opperations (e.g. concatenating tensors) that are repeated over and over. This makes the network _slow_ to train.\n",
    "\n",
    "There's a way around this, but it takes some additional engineering. We can represent this graph as several matrices to capture the weights and connections.\n",
    "\n",
    "Let's start with the connections. Instead of having a graph stored as a list of edges we could use a matrix to define all the connections. Here are the connections in the above graph. There's a 1 for every edge and a 0 for each set of nodes that are not connected (exempted for simplicity). \n",
    "\n",
    "```\n",
    "  A B C D E \n",
    "A     1\n",
    "B       1 1\n",
    "C         1\n",
    "D         1\n",
    "E\n",
    "```\n",
    "\n",
    "Let's set this observation aside for now. We'll return to it soon. \n",
    "\n",
    "\n",
    "For now we'll think about the graph. We want to _group_ nodes together that can be processed at the same time. We'll start by ordering the nodes such that we visit every node only after it's dependieces have been visited:\n",
    "```\n",
    "A B C D E \n",
    "```\n",
    "\n",
    "Then we look for sets of nodes that can be run without needing the any dependencies that haven't been run:\n",
    "```\n",
    "A B C D E \n",
    "A B         # set 1\n",
    "    C D E   # set 2\n",
    "            # set 3\n",
    "```\n",
    "\n",
    "Now we inspect each set (starting from the end and working backwards) to check if there are dependencies that _aren't_ in the previous set. \n",
    "\n",
    "```\n",
    "A B C D E  \n",
    "A B         # set 1 also needs: \n",
    "    C D     # set 2 also needs:\n",
    "        E   # set 3 also needs: B\n",
    "```\n",
    "\n",
    "For each set we'll add the nodes that were needed to the previous set. This give us:\n",
    "```\n",
    "A B, B C D, E\n",
    "```\n",
    "\n",
    "This is the information that needs to be produced from each dense layer. In the case of set 2 we also need to preserve instead of produce an output (B). We can do this by setting it's weight to 1 and bias to 0. For this we'll use the same connections in the matrix above. Let's sketch out these weight matrices:\n",
    "```\n",
    "  B C D\n",
    "A   #\n",
    "B 1   #\n",
    "\n",
    "  E\n",
    "B #\n",
    "C #\n",
    "D #\n",
    "```\n",
    "\n",
    "So we can represent these five layers as two layers by disallowing some connections. If we wanted to increase the number of units we could end up with something like this:\n",
    "```\n",
    "\n",
    "  B C C D D\n",
    "A   # #\n",
    "B 1     # #\n",
    "```\n",
    "```\n",
    "\n",
    "  E\n",
    "B #\n",
    "C #\n",
    "C #\n",
    "D #\n",
    "D #\n",
    "```\n",
    "\n",
    "Look at the first matrix. We've gone from having three 0s to five. As the number of nodes and units per node increases the proporiton of values that are 0 will keep increasing. This is a huge waste of memory and something we didn't have to think about when each of these layers were being stored separately. \n",
    "\n",
    "There's a trick we can use to get around this. We can use _sparse_ matrices which expect many values to be 0 and are optimized to save memory. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8cada",
   "metadata": {},
   "source": [
    "Let's consider an example. Here we have two nodes represented that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8bdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_i = torch.concat([torch.randn([2, 5]), 2*torch.ones( [2, 5])], axis =1)\n",
    "\n",
    "# desired behavior:\n",
    "# unity on part of it\n",
    "y_i = xs_i*torch.concat([torch.linspace(1, 5, 5), torch.zeros(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.zeros([10,10])\n",
    "xx[0:5, 0:5] = torch.randn(5, 5)\n",
    "xx[5:10, 5:10] = torch.eye(5)\n",
    "# px.imshow(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0064621",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SparseLinearCustom(\n",
    "    10, 10,\n",
    "    connectivity   = torch.LongTensor(xx.to_sparse().indices()),\n",
    "    custom_weights = xx.to_sparse().values(), \n",
    "    custom_bias    = torch.tensor([1., 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.weight.to_dense().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62664197",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(xs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf09c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join([e for e in dir(model) if e[0]!= '_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1928442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.weight.grad\n",
    "# model.get_parameter('weights').grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21640739",
   "metadata": {},
   "outputs": [],
   "source": [
    "[e.grad for e in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for i in range(1000):\n",
    "    loss = loss_fn(model(xs_i), y_i)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # zero select gradients\n",
    "    model.weights.grad[-5:] = 0\n",
    "    model.bias.grad[-5:] = 0\n",
    "    # break\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.weight.to_dense().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fac26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sparselinear as sl\n",
    "# model = sl.SparseLinear(20, 20, \n",
    "#                         # connectivity=torch.LongTensor([[1, 2],[1, 2]]))\n",
    "#                         connectivity=torch.LongTensor(torch.eye(20).to_sparse().indices())\n",
    "# )\n",
    "\n",
    "# px.imshow(model.weight.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a75690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "# loss_fn = nn.MSELoss()\n",
    "\n",
    "# xs_i = torch.randn([2, 20])\n",
    "\n",
    "# for i in range(1000):\n",
    "#     loss = loss_fn(model(xs_i), xs_i)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if i % 100 == 0:\n",
    "#         print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e78e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(model.weight.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abc093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo with initialized weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../nbs_artifacts/01.25_g2fc_demo_FC_graph_by_sparse/'\n",
    "save_prefix = [e for e in cache_path.split('/') if e != ''][-1]\n",
    "\n",
    "# Run settings: \n",
    "max_epoch  = 202\n",
    "batch_size = 256\n",
    "\n",
    "# VNN settings:\n",
    "default_out_nodes_inp   = 3 #  4\n",
    "default_out_nodes_edge  = 3 # 32\n",
    "default_out_nodes_out   = 1\n",
    "\n",
    "default_drop_nodes_inp  = 0.0\n",
    "default_drop_nodes_edge = 0.\n",
    "default_drop_nodes_out  = 0.0\n",
    "\n",
    "default_reps_nodes_inp  = 1\n",
    "default_reps_nodes_edge = 1\n",
    "default_reps_nodes_out  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f9b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c940c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu_num = 0\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if use_gpu_num in [0, 1]: \n",
    "    torch.cuda.set_device(use_gpu_num)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnvDL.dlfn import kegg_connections_build, kegg_connections_clean, kegg_connections_append_y_hat, kegg_connections_sanitize_names\n",
    "from EnvDL.dlfn import VNNHelper, VisableNeuralNetwork, Linear_block_reps\n",
    "from EnvDL.dlfn import ListDataset, plVNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cb08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Same setup as above to create kegg_gene_brite\n",
    "X = g2fc_datawrapper()\n",
    "X.set_split()\n",
    "X.load_all(name_list = ['obs_geno_lookup', 'YMat', 'KEGG_slices',], store=True) \n",
    "X.calc_cs('YMat', version = 'np', filter = 'val:train')\n",
    "ACGT_gene_slice_list =     X.get('KEGG_slices', ops_string='')\n",
    "parsed_kegg_gene_entries = X.get('KEGG_entries')\n",
    "\n",
    "\n",
    "# Restrict to only those with pathway\n",
    "kegg_gene_brite = [e for e in parsed_kegg_gene_entries if 'BRITE' in e.keys()]\n",
    "\n",
    "# also require to have a non-empty path\n",
    "kegg_gene_brite = [e for e in kegg_gene_brite if not e['BRITE']['BRITE_PATHS'] == []]\n",
    "\n",
    "print('Retaining '+ str(round(len(kegg_gene_brite)/len(parsed_kegg_gene_entries), 4)*100)+'%, '+str(len(kegg_gene_brite)\n",
    "    )+'/'+str(len(parsed_kegg_gene_entries)\n",
    "    )+' Entries'\n",
    "    )\n",
    "# kegg_gene_brite[1]['BRITE']['BRITE_PATHS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_connections = kegg_connections_build(kegg_gene_brite = kegg_gene_brite, \n",
    "                                          n_genes = 6067) \n",
    "kegg_connections = kegg_connections_clean(         kegg_connections = kegg_connections)\n",
    "kegg_connections = kegg_connections_append_y_hat(  kegg_connections = kegg_connections)\n",
    "kegg_connections = kegg_connections_sanitize_names(kegg_connections = kegg_connections, \n",
    "                                                   replace_chars = {'.':'_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_kegg_connections = kegg_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e00cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96fbe289",
   "metadata": {},
   "source": [
    "## Example with hypothetical graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def name_cleanup(input = '7_1_2_1P-TypeH+-ExportingTransporter', newline_char_threshold = 10):\n",
    "    inp = input\n",
    "    # remove \"7_1_2_1\" type from front of name\n",
    "    rm_front = re.match(r'^[\\d|_]+', inp)\n",
    "    if rm_front:\n",
    "        inp = inp[rm_front.span()[1]:]\n",
    "\n",
    "    word_splits = [e.span()[0] for e in re.finditer('[a-z][A-Z]', inp)]\n",
    "\n",
    "    word_list = []\n",
    "    i = 0\n",
    "    for jth in range(len(word_splits)):\n",
    "        j = word_splits[jth]\n",
    "        j += 1\n",
    "        word_list += [inp[i:j]]\n",
    "        i = j\n",
    "\n",
    "        if jth+1 == len(word_splits):\n",
    "            word_list += [inp[i:len(inp)]]\n",
    "\n",
    "    x = []\n",
    "    n = 0\n",
    "    for e in word_list:\n",
    "        n += len(e)\n",
    "        if n >= newline_char_threshold:\n",
    "            x += ['\\n'+e]\n",
    "            n = len(e)\n",
    "        else:\n",
    "            x += [' '+e]\n",
    "    x = ''.join(x).strip('^ ')\n",
    "\n",
    "    # if the name was only numerics keep the name as is\n",
    "    if x != '':\n",
    "        pass\n",
    "    elif inp != '':\n",
    "        x = inp\n",
    "    elif inp == '':\n",
    "        x = input\n",
    "\n",
    "    return(x)\n",
    "\n",
    "# name_cleanup(input = '987987897', newline_char_threshold = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0795d",
   "metadata": {},
   "source": [
    "We'll begin by defining a hypothetical graph. This ultimately will come from KEGG but for now we'll arbitrarily define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb648a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "kegg_connections = {\n",
    " 'A': ['100278565'],\n",
    " 'B': ['100278565'],\n",
    " 'C': ['100383860'],\n",
    " 'D': ['B', 'C'],\n",
    " 'y_hat': ['A', 'C', 'D']}\n",
    "\n",
    "dot = Digraph()\n",
    "for key in kegg_connections.keys():\n",
    "    key_label = name_cleanup(input = key, newline_char_threshold = 20)+'\\n '\n",
    "    dot.node(key, key_label)\n",
    "    for value in kegg_connections[key]:\n",
    "        # edge takes a head/tail whereas edges takes name pairs concatednated (A, B -> AB)in a list\n",
    "        dot.edge(value, key)    \n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what if we want to have multiple layers per node? Insert a 'pipe' to the new node.\n",
    "# In practice it probably makes sense to use VNNHelper to identify the non-input nodes or other subsets that might get custom treatment. \n",
    "# Filtering these would also be as simple as looking for `values == []`\n",
    "\n",
    "# node_name = 'A'\n",
    "\n",
    "# node_name_new = node_name +'2'\n",
    "# # update all the values so that the nodes which depend on the updated node point to the new node\n",
    "# for key in kegg_connections.keys():\n",
    "#     kegg_connections[key] = [e if e != node_name else node_name_new for e in kegg_connections[key]]\n",
    "# # Add the new node with the old node pointing to it. \n",
    "# kegg_connections[node_name_new] = [node_name]\n",
    "\n",
    "\n",
    "\n",
    "# dot = Digraph()\n",
    "# for key in kegg_connections.keys():\n",
    "#     key_label = name_cleanup(input = key, newline_char_threshold = 20)+'\\n '\n",
    "#     dot.node(key, key_label)\n",
    "#     for value in kegg_connections[key]:\n",
    "#         # edge takes a head/tail whereas edges takes name pairs concatednated (A, B -> AB)in a list\n",
    "#         dot.edge(value, key)    \n",
    "\n",
    "# dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e36b24",
   "metadata": {},
   "source": [
    "Now using the `VNNHelper` we build a lookup dictionary to go from the name for a gene to the location in the vals list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize helper for input nodes\n",
    "myvnn = VNNHelper(edge_dict = kegg_connections)\n",
    "\n",
    "myvnn.nodes_inp[0:10]\n",
    "\n",
    "# Get a mapping of brite names to tensor list index\n",
    "find_names = myvnn.nodes_inp # e.g. ['100383860', '100278565', ... ]\n",
    "lookup_dict = {}\n",
    "\n",
    "# the only difference lookup_dict and brite_node_to_list_idx_dict above is that this is made using the full set of genes in the list \n",
    "# whereas that is made using kegg_gene_brite which is a subset\n",
    "for i in range(len(parsed_kegg_gene_entries)):\n",
    "    if 'BRITE' not in parsed_kegg_gene_entries[i].keys():\n",
    "        pass\n",
    "    elif parsed_kegg_gene_entries[i]['BRITE']['BRITE_PATHS'] == []:\n",
    "        pass\n",
    "    else:\n",
    "        name = parsed_kegg_gene_entries[i]['BRITE']['BRITE_PATHS'][0][-1]\n",
    "        if name in find_names:\n",
    "            lookup_dict[name] = i\n",
    "lookup_dict    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c415ad9",
   "metadata": {},
   "source": [
    "Calculate the input sizes for each node in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brite_node_to_list_idx_dict = {}\n",
    "for i in range(len(kegg_gene_brite)):\n",
    "    brite_node_to_list_idx_dict[str(kegg_gene_brite[i]['BRITE']['BRITE_PATHS'][0][-1])] = i        \n",
    "\n",
    "# Get the input sizes for the graph\n",
    "size_in_zip = zip(myvnn.nodes_inp, [np.prod(ACGT_gene_slice_list[lookup_dict[e]].shape[1:]) for e  in myvnn.nodes_inp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e012593",
   "metadata": {},
   "source": [
    "Now that information gets used to set the input sizes for each node and then set up the other attributes of each of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init input node sizes\n",
    "myvnn.set_node_props(key = 'inp', node_val_zip = size_in_zip)\n",
    "\n",
    "# init node output sizes\n",
    "myvnn.set_node_props(key = 'out', node_val_zip = zip(myvnn.nodes_inp, [default_out_nodes_inp  for e in myvnn.nodes_inp]))\n",
    "myvnn.set_node_props(key = 'out', node_val_zip = zip(myvnn.nodes_edge,[default_out_nodes_edge for e in myvnn.nodes_edge]))\n",
    "myvnn.set_node_props(key = 'out', node_val_zip = zip(myvnn.nodes_out, [default_out_nodes_out  for e in myvnn.nodes_out]))\n",
    "\n",
    "\n",
    "# # options should be controlled by node_props\n",
    "myvnn.set_node_props(key = 'flatten', node_val_zip = zip(\n",
    "    myvnn.nodes_inp, \n",
    "    [True for e in myvnn.nodes_inp]))\n",
    "\n",
    "myvnn.set_node_props(key = 'reps', node_val_zip = zip(myvnn.nodes_inp, [default_reps_nodes_inp  for e in myvnn.nodes_inp]))\n",
    "myvnn.set_node_props(key = 'reps', node_val_zip = zip(myvnn.nodes_edge,[default_reps_nodes_edge for e in myvnn.nodes_edge]))\n",
    "myvnn.set_node_props(key = 'reps', node_val_zip = zip(myvnn.nodes_out, [default_reps_nodes_out  for e in myvnn.nodes_out]))\n",
    "\n",
    "myvnn.set_node_props(key = 'drop', node_val_zip = zip(myvnn.nodes_inp, [default_drop_nodes_inp  for e in myvnn.nodes_inp]))\n",
    "myvnn.set_node_props(key = 'drop', node_val_zip = zip(myvnn.nodes_edge,[default_drop_nodes_edge for e in myvnn.nodes_edge]))\n",
    "myvnn.set_node_props(key = 'drop', node_val_zip = zip(myvnn.nodes_out, [default_drop_nodes_out  for e in myvnn.nodes_out]))\n",
    "\n",
    "# init edge node input size (propagate forward input/edge outpus)\n",
    "myvnn.calc_edge_inp()\n",
    "\n",
    "# myvnn.mk_digraph(include = ['node_name', 'inp_size', 'out_size'])\n",
    "# myvnn.mk_digraph(include = [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dfb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnvDL.dlfn import plDNN_general, BigDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2dc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = X.get('KEGG_slices', ops_string='asarray from_numpy float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to the tensors that will be used\n",
    "vals = [vals[lookup_dict[i]] for i in myvnn.nodes_inp]\n",
    "# send to gpu\n",
    "# vals = [val.to('cuda') for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378de265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace lookup so that it matches the lenght of the input tensors\n",
    "new_lookup_dict = {}\n",
    "for i in range(len(myvnn.nodes_inp)):\n",
    "    new_lookup_dict[myvnn.nodes_inp[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e14200",
   "metadata": {},
   "source": [
    "### Calculate nodes membership in each matrix and positions within each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ba47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myvnn.nodes_inp\n",
    "# vals[new_lookup_dict['100282167']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: \n",
    "\n",
    "node_props = myvnn.node_props\n",
    "# Linear_block = Linear_block_reps,\n",
    "edge_dict = myvnn.edge_dict\n",
    "dependancy_order = myvnn.dependancy_order\n",
    "node_to_inp_num_dict = new_lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221fdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a pass through the dependency order and check that each node comes after all of its dependanies.\n",
    "\n",
    "# check dep order\n",
    "tally = []\n",
    "for d in dependancy_order:\n",
    "    if edge_dict[d] == []:\n",
    "        tally.append(d)\n",
    "    elif False not in [True if e in tally else False for e in edge_dict[d]]:\n",
    "        tally.append(d)\n",
    "    else:\n",
    "        print('error!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ceb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now go through each of the nodes and create chunks containing all the nodes that _do not depend_ on any other nodes in the current chunk. \n",
    "\n",
    "#            - A -------\n",
    "#           /           \\\n",
    "# 100278565 -- B -- D -- y_hat\n",
    "#                  /    /\n",
    "# 100383860 -> C -------\n",
    "\n",
    "#     ['100278565', '100383860',      'C', 'B', 'D', 'A', 'y_hat'] # Example: `dependancy_order` \n",
    "# {0: ['100278565', '100383860'], 1: ['C', 'B', 'A'], 2: ['D'], 3: ['y_hat']} # Example: `d_out`\n",
    "\n",
    "# build output nodes \n",
    "d_out = {0:[]}\n",
    "for d in dependancy_order:\n",
    "    if edge_dict[d] == []:\n",
    "        d_out[min(d_out.keys())].append(d)\n",
    "    else:\n",
    "        # print((d, edge_dict[d]))\n",
    "\n",
    "        d_out_i = 1+max(sum([[key for key in d_out.keys() if e in d_out[key]]\n",
    "                   for e in edge_dict[d]], []))\n",
    "        \n",
    "        if d_out_i not in d_out.keys():\n",
    "            d_out[d_out_i] = []\n",
    "        d_out[d_out_i].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c890ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {3: ['C', 'A'], 2: [], 1: []}\n",
    "\n",
    "# build index of dependencies that are not calculated in the previous set\n",
    "d_eye = {}\n",
    "tally = []\n",
    "for i in range(max(d_out.keys()), min(d_out.keys()), -1):\n",
    "    # print(i)\n",
    "    nodes_needed = sum([edge_dict[e] for e in d_out[i]], [])+tally\n",
    "    # check against what is there and then dedupe\n",
    "    nodes_needed = [e for e in nodes_needed if e not in d_out[i-1]]\n",
    "    nodes_needed = list(set(nodes_needed))\n",
    "    tally = nodes_needed\n",
    "    d_eye[i] = nodes_needed\n",
    "    \n",
    "# [len(d_eye[i]) for i in d_eye.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an index of the set of nodes and which values are in the inputs, outputs, or outputs that are not calcuated in this set. \n",
    "\n",
    "# {3: {'out': ['y_hat'],                  'inp': ['D'],                      'eye': ['C', 'A']},\n",
    "#  2: {'out': ['D'],                      'inp': ['C', 'B', 'A'],            'eye': []},\n",
    "#  1: {'out': ['C', 'B', 'A'],            'inp': ['100278565', '100383860'], 'eye': []},\n",
    "#  0: {'out': ['100278565', '100383860'], 'inp': ['100278565', '100383860'], 'eye': []}}\n",
    "\n",
    "dd = {}\n",
    "for i in d_eye.keys():\n",
    "    dd[i] = {'out': d_out[i],\n",
    "             'inp': d_out[i-1],\n",
    "             'eye': d_eye[i]}\n",
    "    \n",
    "# plus special 0 layer that handles the snps\n",
    "dd[0] = {'out': d_out[0],\n",
    "         'inp': d_out[0],\n",
    "         'eye': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the output nodes' inputs are satisfied by the same layer's inputs (inp and eye)\n",
    "\n",
    "for i in dd.keys():\n",
    "    # out node in each\n",
    "    for e in dd[i]['out']:\n",
    "        # node depends in inp/eye\n",
    "        node_pass_list = [True if ee in dd[i]['inp']+dd[i]['eye'] else False \n",
    "                          for ee in edge_dict[e]]\n",
    "        if False not in node_pass_list:\n",
    "            pass\n",
    "        else:\n",
    "            print('exit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out information about the size of the weight matrices.\n",
    "print(\"Layer\\t#In\\t#Out\")\n",
    "for i in range(min(dd.keys()), max(dd.keys())+1, 1):\n",
    "    node_in      = [node_props[e]['out'] for e in dd[i]['inp']+dd[i  ]['eye'] ]\n",
    "    if i == max(dd.keys()):\n",
    "        node_out = [node_props[e]['out'] for e in dd[i]['out'] ]\n",
    "    else:\n",
    "        node_out = [node_props[e]['out'] for e in dd[i]['out']+dd[i+1]['eye']]\n",
    "    print(f'{i}:\\t{sum(node_in)}\\t{sum(node_out)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ffc63",
   "metadata": {},
   "source": [
    "### Creating Structured Matrices for Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00777e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class structured_layer_info:\n",
    "    def __init__(self, i, \n",
    "                 dd,  # {1: {'out': ['OtherTubulinModificationProteins',\n",
    "                      #      'inp': [\n",
    "                      #      'eye': [\n",
    "                 node_props, # {'KeggOrthology(Ko)[Br-Zma00001]': {'out': 1, 'reps': 1, 'drop': 0.0, 'inp': 7},\n",
    "                 edge_dict,\n",
    "                 as_sparse = False\n",
    "                 ):\n",
    "        self.row_inp = dd[i]['inp']\n",
    "        self.row_eye = dd[i]['eye']\n",
    "\n",
    "        self.col_out = dd[i]['out']\n",
    "        self.col_eye = []\n",
    "        if i+1 in dd.keys():\n",
    "            self.col_eye = dd[i+1]['eye'] \n",
    "\n",
    "        # build lookup dicts of the information on each side\n",
    "        row_nodes = [e for e in self.row_inp+self.row_eye]\n",
    "        col_nodes = [e for e in self.col_out+self.col_eye]\n",
    "\n",
    "        if i == min(dd.keys()):\n",
    "            # print('check')\n",
    "            row_sizes = [node_props[e]['inp'] for e in row_nodes]\n",
    "        else:\n",
    "            row_sizes = [node_props[e]['out'] for e in row_nodes]\n",
    "        col_sizes = [node_props[e]['out'] for e in col_nodes]\n",
    "\n",
    "        row_sizes = torch.Tensor(row_sizes).to(torch.int)\n",
    "        row_stop  = torch.cumsum(row_sizes, 0)\n",
    "        row_start = torch.concat([torch.Tensor([0]).to(torch.int), row_stop[0:-1]])\n",
    "\n",
    "        col_sizes = torch.Tensor(col_sizes).to(torch.int)\n",
    "        col_stop  = torch.cumsum(col_sizes, 0)\n",
    "        col_start = torch.concat([torch.Tensor([0]).to(torch.int), col_stop[0:-1]])\n",
    "\n",
    "        self.row_info = {}\n",
    "        for j in range(len(row_sizes)):\n",
    "            self.row_info[row_nodes[j]]= {\n",
    "                'size': row_sizes[j],\n",
    "                'stop':  row_stop[j],\n",
    "                'start': row_start[j],\n",
    "            }\n",
    "\n",
    "        self.col_info = {}\n",
    "        for j in range(len(col_sizes)):\n",
    "            self.col_info[col_nodes[j]]= {\n",
    "                'size': col_sizes[j],\n",
    "                'stop':  col_stop[j],\n",
    "                'start': col_start[j],\n",
    "            }\n",
    "    \n",
    "        # bias shape does not change based on sparse/none\n",
    "        self.bias            = torch.zeros([              col_stop[-1]])\n",
    "        self.bias_eye_bool   = torch.zeros([              col_stop[-1]]) # 1 if is eye\n",
    "\n",
    "        if not as_sparse:\n",
    "            ## Init weight & bias matrix ====\n",
    "            self.weight          = torch.zeros([row_stop[-1], col_stop[-1]])\n",
    "            self.weight_bool     = torch.zeros([row_stop[-1], col_stop[-1]]) # 1 if is weight\n",
    "            self.weight_eye_bool = torch.zeros([row_stop[-1], col_stop[-1]]) # 1 if is eye\n",
    "\n",
    "            for e in self.col_out:\n",
    "                c_size = self.col_info[e]['size']\n",
    "                # print(f'i {i} key min {min(dd.keys())}')\n",
    "                if i == min(dd.keys()):\n",
    "                    inps = [e]\n",
    "                else:\n",
    "                    inps = edge_dict[e]\n",
    "                # print(f'inps: {inps}')\n",
    "                # r_size_total = sum([self.row_info[ee]['size'] for ee in inps])\n",
    "                # W = torch.empty(r_size_total, c_size)\n",
    "                # W = torch.nn.init.kaiming_normal_(W, a=0, mode='fan_in', nonlinearity='relu')\n",
    "            \n",
    "                c1 = self.col_info[e]['start']\n",
    "                c2 = self.col_info[e]['stop']\n",
    "\n",
    "                # W_start = 0\n",
    "                # print(W.shape)\n",
    "                for inp in inps:\n",
    "                    r1 = self.row_info[inp]['start']\n",
    "                    r2 = self.row_info[inp]['stop']\n",
    "                    slice_size = r2-r1\n",
    "                    # W_end = W_start + slice_size\n",
    "                    # print(W_start, W_end)\n",
    "                    # self.weight[r1:r2, c1:c2] = W[W_start:W_end]\n",
    "\n",
    "                    # Use nn.Linear to initialize the matrix instead of doing it manually.\n",
    "                    xx = nn.Linear(slice_size, c_size)\n",
    "                    W = xx.weight.clone().detach().requires_grad_(False)\n",
    "                    # print(f'{W.shape} {self.weight[r1:r2, c1:c2].shape}')\n",
    "                    B = xx.bias.clone().detach().requires_grad_(False)\n",
    "                    self.weight[r1:r2, c1:c2] = W#.swapaxes(0,1)                                                          # <- transposed to match nn.Linear\n",
    "                    self.weight_bool[r1:r2, c1:c2] = torch.ones(W.shape)#.swapaxes(0,1) # Fill in gradient bool matrix    # <- transposed to match nn.Linear\n",
    "                    self.bias[c1:c2] = B\n",
    "                    # W_start = W_end        \n",
    "                    \n",
    "            for e in self.col_eye:\n",
    "                c_size = self.col_info[e]['size']\n",
    "                c1 = self.col_info[e]['start']\n",
    "                c2 = self.col_info[e]['stop']\n",
    "                r1 = self.row_info[e]['start']\n",
    "                r2 = self.row_info[e]['stop']\n",
    "\n",
    "                W = torch.eye(c_size)\n",
    "                self.weight[r1:r2, c1:c2] = W\n",
    "                # FIXME testing if not allowing gradients on unity entries is causing the problem. If it is then either \n",
    "                # 1. pass through gradients from one layer to the next (and or)\n",
    "                # 2. re-set these values to unity after each update. \n",
    "                self.weight_eye_bool[r1:r2, c1:c2] = torch.eye(c_size)#.swapaxes(0,1)                                     # <- transposed to match nn.Linear\n",
    "\n",
    "            # if as_sparse:\n",
    "            #     self.weight      = self.weight.to_sparse()\n",
    "            #     self.weight_bool = self.weight_bool.to_sparse()\n",
    "            #     self.weight_eye_bool = self.weight_bool.to_sparse()\n",
    "            #     # self.bias = self.bias\n",
    "\n",
    "            ## Init identity components of matrix ====\n",
    "            # 1.0 if identity otherwise 0\n",
    "            for e in self.col_eye:\n",
    "                self.bias_eye_bool[self.col_info[e]['start']:self.col_info[e]['stop']] = 1.0\n",
    "            if self.col_eye != []:\n",
    "                self.bias_eye_bool = self.bias_eye_bool \n",
    "\n",
    "\n",
    "            # Transpose to match as_sparse output (and desired input for custom sparse linear layer)\n",
    "            self.weight          = self.weight.swapaxes(0,1)\n",
    "            self.weight_bool     = self.weight_bool.swapaxes(0,1)\n",
    "            self.weight_eye_bool = self.weight_eye_bool.swapaxes(0,1)\n",
    "\n",
    "        elif as_sparse:\n",
    "            ## Init weight & bias matrix ====\n",
    "            # self.weight          = torch.zeros([row_stop[-1], col_stop[-1]])\n",
    "            # self.weight_bool     = torch.zeros([row_stop[-1], col_stop[-1]]) # 1 if is weight\n",
    "            # self.weight_eye_bool = torch.zeros([row_stop[-1], col_stop[-1]]) # 1 if is eye\n",
    "\n",
    "            # accumulators\n",
    "            self.w_acc_indices = None\n",
    "            self.w_acc_values = None\n",
    "            \n",
    "            for e in self.col_out:\n",
    "                c_size = self.col_info[e]['size']\n",
    "                # print(f'i {i} key min {min(dd.keys())}')\n",
    "                if i == min(dd.keys()):\n",
    "                    inps = [e]\n",
    "                else:\n",
    "                    inps = edge_dict[e]\n",
    "            \n",
    "                c1 = self.col_info[e]['start']\n",
    "                c2 = self.col_info[e]['stop']\n",
    "\n",
    "                for inp in inps:\n",
    "                    r1 = self.row_info[inp]['start']\n",
    "                    r2 = self.row_info[inp]['stop']\n",
    "                    slice_size = r2-r1\n",
    "\n",
    "                    # Use nn.Linear to initialize the matrix instead of doing it manually.\n",
    "                    xx = nn.Linear(slice_size, c_size)\n",
    "                    W = xx.weight.clone().detach().requires_grad_(False)\n",
    "                    B = xx.bias.clone().detach().requires_grad_(False)\n",
    "\n",
    "                    W = W.to_sparse()\n",
    "\n",
    "                    sparse_indices = W.indices()+torch.tensor([[c1],\n",
    "                                                               [r1]])\n",
    "                    sparse_values  = W.values()\n",
    "\n",
    "                    # W = torch.sparse_coo_tensor(sparse_indices, sparse_values) # optional list of shape\n",
    "\n",
    "                    # if self.weight == None:\n",
    "                    #     self.weight = W\n",
    "                    # else: \n",
    "                    #     self.weight = torch.concat([self.weight, W], axis = 1)\n",
    "\n",
    "                    # sparse_indices = torch.concat([\n",
    "                    #     torch.tensor(sum([[ii for i in range(r1, r2)] for ii in range(c1, c2)], []))[None, :],\n",
    "                    #     torch.tensor(sum([[i for i in range(r1, r2)] for ii in range(c1, c2)], []))[None, :]\n",
    "                    #     ], axis = 0)\n",
    "                    # # [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "                    # # [3, 4, 5, 3, 4, 5, 3, 4, 5]\n",
    "                    # # print(sparse_indices)\n",
    "\n",
    "                    # sparse_values = W.reshape(-1)\n",
    "\n",
    "                    if self.w_acc_indices == None:\n",
    "                        self.w_acc_indices = sparse_indices\n",
    "                    else:\n",
    "                        self.w_acc_indices = torch.concat([self.w_acc_indices, sparse_indices], axis = 1 )\n",
    "\n",
    "                    if self.w_acc_values == None:\n",
    "                        self.w_acc_values = sparse_values\n",
    "                    else:\n",
    "                        self.w_acc_values = torch.concat([self.w_acc_values, sparse_values],    axis = 0 )\n",
    "\n",
    "                    # self.weight_bool[r1:r2, c1:c2] = torch.ones(W.shape).swapaxes(0,1) # Fill in gradient bool matrix    # <- transposed to match nn.Linear\n",
    "                    self.bias[c1:c2] = B\n",
    "\n",
    "\n",
    "            bias_grad_bool = torch.zeros(self.bias.shape)\n",
    "            bias_grad_bool[self.bias != 0] = 1\n",
    "            self.bias_grad_bool = 1+bias_grad_bool # Encode a weight as 2, eye as 1. This is more work here but allows for use of a sparse matrix below without dropping values that are eye (0) and messing up the length relative to the gradients (because gradients are calculated for the valeues at 1 and then have to be zeroed.)\n",
    "\n",
    "\n",
    "            self.w_eye_acc_indices = None\n",
    "            self.w_eye_acc_values  = None\n",
    "            self.weight_eye_bool   = None\n",
    "\n",
    "            for e in self.col_eye:\n",
    "                c_size = self.col_info[e]['size']\n",
    "                c1 = self.col_info[e]['start']\n",
    "                c2 = self.col_info[e]['stop']\n",
    "                r1 = self.row_info[e]['start']\n",
    "                r2 = self.row_info[e]['stop']\n",
    "\n",
    "                W = torch.eye(c_size)\n",
    "\n",
    "                W = W.to_sparse()\n",
    "\n",
    "                sparse_indices = W.indices()+torch.tensor([[c1],\n",
    "                                                           [r1]])\n",
    "                sparse_values = W.values()\n",
    "\n",
    "                if self.w_eye_acc_indices == None:\n",
    "                    self.w_eye_acc_indices = sparse_indices\n",
    "                else:\n",
    "                    self.w_eye_acc_indices = torch.concat([self.w_eye_acc_indices, sparse_indices], axis = 1 )\n",
    "\n",
    "                if self.w_eye_acc_values == None:\n",
    "                    self.w_eye_acc_values = sparse_values\n",
    "                else:\n",
    "                    self.w_eye_acc_values = torch.concat([self.w_eye_acc_values, sparse_values],    axis = 0 )\n",
    "\n",
    "\n",
    "            ## Init identity components of matrix ====\n",
    "            # 1.0 if identity otherwise 0\n",
    "            for e in self.col_eye:\n",
    "                self.bias_eye_bool[self.col_info[e]['start']:self.col_info[e]['stop']] = 1.0\n",
    "            if self.col_eye != []:\n",
    "                self.bias_eye_bool = self.bias_eye_bool    \n",
    "\n",
    "\n",
    "            self.weight = torch.sparse_coo_tensor(\n",
    "                torch.concat([e for e in [self.w_acc_indices, self.w_eye_acc_indices] if e != None], axis = 1 ), \n",
    "                torch.concat([e for e in [self.w_acc_values, self.w_eye_acc_values] if e != None],   axis = 0 )\n",
    "                )    \n",
    "            self.weight = self.weight.coalesce()\n",
    "\n",
    "            # if self.w_eye_acc_indices != None:\n",
    "            #     self.weight_eye_bool = torch.sparse_coo_tensor(\n",
    "            #         self.w_eye_acc_indices, \n",
    "            #         self.w_eye_acc_values \n",
    "            #         )    \n",
    "            \n",
    "\n",
    "            self.weight_grad_bool = None\n",
    "            if self.w_acc_indices != None:\n",
    "                # self.weight_grad_bool = torch.sparse_coo_tensor(\n",
    "                #     self.w_acc_indices, \n",
    "                #     torch.ones(self.w_acc_values.shape),\n",
    "                #     self.weight.shape \n",
    "                # )\n",
    "                \n",
    "                # Encode a weight as 2, eye as 1\n",
    "                # to get back only weights:  x-1\n",
    "                # to get back only eyes: -1*(x-2)  \n",
    "                if ((self.w_acc_values is not None) and \n",
    "                    (self.w_eye_acc_values is not None)):\n",
    "                    self.weight_grad_bool = torch.sparse_coo_tensor(\n",
    "                        torch.concat([e for e in [self.w_acc_indices, self.w_eye_acc_indices] if e != None], axis = 1 ), \n",
    "                        torch.concat([e for e in [1+torch.ones(self.w_acc_values.shape),   # weights are 2\n",
    "                                                    torch.ones(self.w_eye_acc_values.shape)# eyes are 1\n",
    "                                                    ] if e != None],   axis = 0 )\n",
    "                        )\n",
    "                elif (self.w_acc_values is not None):\n",
    "                    self.weight_grad_bool = torch.sparse_coo_tensor(\n",
    "                        self.w_acc_indices,\n",
    "                        1+torch.ones(self.w_acc_values.shape)\n",
    "                        )\n",
    "                elif (self.w_eye_acc_values is not None):\n",
    "                    self.weight_grad_bool = torch.sparse_coo_tensor(\n",
    "                        self.w_eye_acc_indices,\n",
    "                        1+torch.ones(self.w_eye_acc_values.shape)\n",
    "                        )\n",
    "                    \n",
    "                self.weight_grad_bool.coalesce()\n",
    "\n",
    "            # clean up attributes that aren't needed for downstream functions \n",
    "            # weight\n",
    "            # bias\n",
    "            # weight_grad_bool\n",
    "            # bias_grad_bool\n",
    "        \n",
    "            # lookup dicts. good to keep\n",
    "            # del self.row_info\n",
    "            # del self.col_info\n",
    "\n",
    "            # del self.row_inp\n",
    "            del self.row_eye\n",
    "    \n",
    "            # del self.col_out\n",
    "            del self.col_eye\n",
    "\n",
    "            del self.bias_eye_bool\n",
    "\n",
    "            del self.weight_eye_bool\n",
    "\n",
    "            del self.w_acc_indices\n",
    "            del self.w_acc_values\n",
    "            del self.w_eye_acc_indices\n",
    "            del self.w_eye_acc_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 2\n",
    "# px.imshow(structured_layer_info(i, dd, node_props, edge_dict, as_sparse = False).weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc39337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(structured_layer_info(i, dd, node_props, edge_dict, as_sparse = True).weight.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_list = [structured_layer_info(i = ii, dd = dd, node_props= node_props, edge_dict = edge_dict, as_sparse=True) for ii in range(0, max(dd.keys())+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[e.weight.shape for e in M_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4831bf",
   "metadata": {},
   "source": [
    "### Setup Dataloader using `M_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed88d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = X.get('KEGG_slices', ops_string='asarray from_numpy float')\n",
    "# restrict to the tensors that will be used\n",
    "vals = torch.concat([vals[lookup_dict[i]].reshape(4926, -1) \n",
    "                     for i in M_list[0].row_inp\n",
    "                    #  for i in dd[0]['inp'] # matches\n",
    "                     ], axis = 1)\n",
    "vals.shape\n",
    "vals = vals.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:train asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float cuda:0')[:, None],\n",
    "    # y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:test asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:val:test asarray from_numpy float cuda:0')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d6dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured_layer_info(2, dd, node_props, edge_dict, as_sparse = True).bias_eye_bool.to_sparse().indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a96137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (structured_layer_info(2, dd, node_props, edge_dict, as_sparse = True).w_eye_acc_indices,\n",
    "# structured_layer_info(2, dd, node_props, edge_dict, as_sparse = True).bias_eye_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f19ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_list):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_list = nn.ModuleList(layer_list)\n",
    " \n",
    "    def forward(self, x):\n",
    "        for l in self.layer_list:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cecd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2\n",
    "# M_list[i].bias_eye_bool.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6022fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sparse(M_list[i].w_eye_acc_indices,\n",
    "# torch.ones(M_list[i].w_eye_acc_indices.shape[1])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4046cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "250c735b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = []\n",
    "for i in range(len(M_list)):\n",
    "    l = SparseLinearCustom(\n",
    "        M_list[i].weight.shape[1], # have to transpose this?\n",
    "        M_list[i].weight.shape[0],\n",
    "        connectivity   = torch.LongTensor(M_list[i].weight.coalesce().indices()),\n",
    "        custom_weights = M_list[i].weight.coalesce().values(), \n",
    "        custom_bias    = M_list[i].bias.clone().detach(), \n",
    "        weight_grad_bool = M_list[i].weight_grad_bool, \n",
    "        bias_grad_bool   = M_list[i].bias_grad_bool#.to_sparse()#.indices()\n",
    "        )\n",
    "\n",
    "    layer_list += [l]\n",
    "    \n",
    "    if i+1 != len(M_list):\n",
    "        layer_list += [nn.ReLU()]\n",
    "\n",
    "\n",
    "\n",
    "model = NeuralNetwork(layer_list)\n",
    "model = model.to('cuda')\n",
    "model(next(iter(training_dataloader))[1])[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.layer_list[4].weight.cpu().to_dense().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.layer_list[4].bias.cpu().to_dense().detach().numpy()[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10877018",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_training = model.layer_list[4].weight.cpu().to_dense().detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601babb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_i, xs_i = next(iter(training_dataloader))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for i in range(1000):\n",
    "    loss = loss_fn(model(xs_i), y_i)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # zero select gradients\n",
    "\n",
    "    for l in model.layer_list:\n",
    "        if isinstance(l, SparseLinearCustom):\n",
    "            if l.weight_grad_bool != None:\n",
    "                # Learnable weight bool: turn 2/1 weight/eye into 0/1\n",
    "                l.weights.grad = l.weights.grad * (-1 + l.weight_grad_bool.coalesce().values())\n",
    "\n",
    "            if l.weight_grad_bool != None:\n",
    "                l.bias.grad    = l.bias.grad    * (-1 + l.bias_grad_bool)\n",
    "\n",
    "    # break\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec181fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_training = model.layer_list[4].weight.cpu().to_dense().detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(after_training - before_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.layer_list[4].weight.cpu().to_dense().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8225208",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.layer_list[4].bias.cpu().to_dense().detach().numpy()[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6756b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xs_i\n",
    "print(x.shape)\n",
    "\n",
    "x = model.layer_list[0](x)\n",
    "print(x.shape)\n",
    "\n",
    "x = model.layer_list[1](x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc48c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = 0.9\n",
    "\n",
    "torch.bernoulli(torch.tensor(pr).repeat(x.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bernoulli(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e23ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756f33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf50adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version to predict enviromental residuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = '../nbs_artifacts/01.03_g2fc_prep_matrices/'\n",
    "load_from = '../nbs_artifacts/01.03_g2fc_prep_matrices/'\n",
    "phno_geno = pd.read_csv(load_from+'phno_geno.csv')\n",
    "phno = phno_geno\n",
    "\n",
    "\n",
    "obs_geno_lookup = np.load(load_from+'obs_geno_lookup.npy') # Phno_Idx  Geno_Idx  Is_Phno_Idx\n",
    "obs_env_lookup = np.load(load_from+'obs_env_lookup.npy')   # Phno_Idx  Env_Idx   Is_Phno_Idx\n",
    "YMat = np.load(load_from+'YMat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80685e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnvDL.dlfn import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create train/test validate indicies from json\n",
    "load_from = '../nbs_artifacts/01.06_g2fc_cluster_genotypes/'\n",
    "\n",
    "split_info = read_split_info(\n",
    "    load_from = '../nbs_artifacts/01.06_g2fc_cluster_genotypes/',\n",
    "    json_prefix = '2023:9:5:12:8:26')\n",
    "\n",
    "temp = phno.copy()\n",
    "temp[['Female', 'Male']] = temp['Hybrid'].str.split('/', expand = True)\n",
    "\n",
    "test_dict = find_idxs_split_dict(\n",
    "    obs_df = temp, \n",
    "    split_dict = split_info['test'][0]\n",
    ")\n",
    "# test_dict\n",
    "\n",
    "# since this is applying predefined model structure no need for validation.\n",
    "# This is included for my future reference when validation is needed.\n",
    "temp = temp.loc[test_dict['train_idx'], ] # restrict before re-aplying\n",
    "\n",
    "val_dict = find_idxs_split_dict(\n",
    "    obs_df = temp, \n",
    "    split_dict = split_info['validate'][0]\n",
    ")\n",
    "# val_dict\n",
    "\n",
    "# test_dict\n",
    "\n",
    "train_idx = test_dict['train_idx']\n",
    "test_idx  = test_dict['test_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb34ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data to get env means\n",
    "# obs_env_lookup   # Phno_Idx  Env_Idx   Is_Phno_Idx\n",
    "\n",
    "YMat_EnvMean = YMat.copy()\n",
    "\n",
    "for i in tqdm(list(set(obs_env_lookup[:, 1]))):\n",
    "    mask = (obs_env_lookup[:, 1] == i)\n",
    "    YMat_EnvMean[mask] = YMat_EnvMean[mask].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df824de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract to get residuals\n",
    "YMat = YMat - YMat_EnvMean\n",
    "# proceed as normal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "YMat_cs = calc_cs(YMat[train_idx])\n",
    "y_cs = apply_cs(YMat, YMat_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = torch.from_numpy(y_cs).to(torch.float)#[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929a047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e049130",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:train asarray from_numpy'),\n",
    "    y =           y_temp[train_idx][:, None].to('cuda'),\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:test asarray from_numpy'),\n",
    "    y =           y_temp[test_idx][:, None].to('cuda'),\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e7dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:test:train asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:test:train asarray from_numpy float cuda:0')[:, None],\n",
    "    # y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:test:test asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:test:test asarray from_numpy float cuda:0')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d10ab7",
   "metadata": {},
   "source": [
    "## Structured Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e83829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(M.weight.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = nn.Linear(M.weight.shape[0], M.weight.shape[1])\n",
    "\n",
    "# xx.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b69c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(xx.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx.weight = torch.nn.Parameter(M.weight.swapaxes(0,1))\n",
    "# xx.weight.requires_grad = True\n",
    "# px.imshow(xx.weight.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = []\n",
    "for i in range(len(M_list)):\n",
    "    l = nn.Linear(M_list[i].weight.shape[0], M_list[i].weight.shape[1])\n",
    "    l.weight.requires_grad = False\n",
    "    l.weight = torch.nn.Parameter(M_list[i].weight.swapaxes(0,1))\n",
    "    l.weight.requires_grad = True\n",
    "\n",
    "    l.bias.requires_grad = False\n",
    "    l.bias = torch.nn.Parameter(M_list[i].bias)\n",
    "    l.bias.requires_grad = True\n",
    "\n",
    "    layer_list += [l]\n",
    "    \n",
    "    if i+1 != len(M_list):\n",
    "        layer_list += [nn.ReLU()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d53c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58109b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = layer_list[-3]\n",
    "\n",
    "# px.imshow(l.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_sparse = SparseLinearCustom(\n",
    "#     l.in_features, \n",
    "#     l.out_features,\n",
    "#     connectivity   = torch.LongTensor(l.weight.to_sparse().indices()),\n",
    "#     custom_weights = l.weight.to_sparse().values(), \n",
    "#     custom_bias    = l.bias.clone().detach()\n",
    "#     )\n",
    "\n",
    "# px.imshow(l_sparse.weight.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbf614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert model with dense matrices to sparse matrices\n",
    "\n",
    "layer_list_new = []\n",
    "for l in layer_list:\n",
    "    if isinstance(l, nn.ReLU):\n",
    "        layer_list_new += [l]\n",
    "    if isinstance(l, nn.Linear):\n",
    "        l_sparse = SparseLinearCustom(\n",
    "            l.in_features, \n",
    "            l.out_features,\n",
    "            connectivity   = torch.LongTensor(l.weight.to_sparse().indices()),\n",
    "            custom_weights = l.weight.to_sparse().values(), \n",
    "            custom_bias    = l.bias.clone().detach()\n",
    "            )\n",
    "        layer_list_new += [l_sparse]\n",
    "\n",
    "\n",
    "del layer_list\n",
    "layer_list = layer_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffe9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cb816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(model.layer_list[-3].weight.to_dense())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1281df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SparseLinearCustom(\n",
    "#     10, 10,\n",
    "#     connectivity   = torch.LongTensor(xx.to_sparse().indices()),\n",
    "#     custom_weights = xx.to_sparse().values(), \n",
    "#     custom_bias    = torch.tensor([1., 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a705f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = NeuralNetwork(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03019d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afff54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(next(iter(training_dataloader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VNN = plDNN_general(model)  \n",
    "\n",
    "optimizer = VNN.configure_optimizers()\n",
    "\n",
    "# logger = TensorBoardLogger(\"tb_vnn_logs\", name=save_prefix)\n",
    "# logger = TensorBoardLogger(\"tb_vnn_logs\", name='02.40_g2fc_G_ACGT_VNN_baseline_SPARSE_match_test_scale')\n",
    "logger = TensorBoardLogger(\"tb_vnn_logs\", name='02.40_g2fc_G_ACGT_VNN_baseline_SPARSE_match_net_size')\n",
    "trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "\n",
    "trainer.fit(model=VNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fb059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c6e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6dc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea19a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa4b4a52",
   "metadata": {},
   "source": [
    "## Example on real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452d33b",
   "metadata": {},
   "source": [
    "## Fit Using VNNHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def name_cleanup(input = '7_1_2_1P-TypeH+-ExportingTransporter', newline_char_threshold = 10):\n",
    "#     inp = input\n",
    "#     # remove \"7_1_2_1\" type from front of name\n",
    "#     rm_front = re.match(r'^[\\d|_]+', inp)\n",
    "#     if rm_front:\n",
    "#         inp = inp[rm_front.span()[1]:]\n",
    "\n",
    "#     word_splits = [e.span()[0] for e in re.finditer('[a-z][A-Z]', inp)]\n",
    "\n",
    "#     word_list = []\n",
    "#     i = 0\n",
    "#     for jth in range(len(word_splits)):\n",
    "#         j = word_splits[jth]\n",
    "#         j += 1\n",
    "#         word_list += [inp[i:j]]\n",
    "#         i = j\n",
    "\n",
    "#         if jth+1 == len(word_splits):\n",
    "#             word_list += [inp[i:len(inp)]]\n",
    "\n",
    "#     x = []\n",
    "#     n = 0\n",
    "#     for e in word_list:\n",
    "#         n += len(e)\n",
    "#         if n >= newline_char_threshold:\n",
    "#             x += ['\\n'+e]\n",
    "#             n = len(e)\n",
    "#         else:\n",
    "#             x += [' '+e]\n",
    "#     x = ''.join(x).strip('^ ')\n",
    "\n",
    "#     # if the name was only numerics keep the name as is\n",
    "#     if x != '':\n",
    "#         pass\n",
    "#     elif inp != '':\n",
    "#         x = inp\n",
    "#     elif inp == '':\n",
    "#         x = input\n",
    "\n",
    "#     return(x)\n",
    "\n",
    "# name_cleanup(input = '987987897', newline_char_threshold = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graphviz import Digraph\n",
    "\n",
    "# # kegg_connections = {\n",
    "# #  'A': ['100278565'],\n",
    "# #  'B': ['100278565'],\n",
    "# #  'C': ['100383860'],\n",
    "# #  'D': ['B', 'C'],\n",
    "# #  'y_hat': ['A', 'D']}\n",
    "\n",
    "# dot = Digraph()\n",
    "# for key in kegg_connections.keys():\n",
    "#     key_label = name_cleanup(input = key, newline_char_threshold = 20)+'\\n '\n",
    "#     dot.node(key, key_label)\n",
    "#     for value in kegg_connections[key]:\n",
    "#         # edge takes a head/tail whereas edges takes name pairs concatednated (A, B -> AB)in a list\n",
    "#         dot.edge(value, key)    \n",
    "\n",
    "# dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711016de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ac803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize helper for input nodes\n",
    "myvnn = VNNHelper(edge_dict = kegg_connections)\n",
    "\n",
    "myvnn.nodes_inp[0:10]\n",
    "\n",
    "# Get a mapping of brite names to tensor list index\n",
    "find_names = myvnn.nodes_inp # e.g. ['100383860', '100278565', ... ]\n",
    "lookup_dict = {}\n",
    "\n",
    "# the only difference lookup_dict and brite_node_to_list_idx_dict above is that this is made using the full set of genes in the list \n",
    "# whereas that is made using kegg_gene_brite which is a subset\n",
    "for i in range(len(parsed_kegg_gene_entries)):\n",
    "    if 'BRITE' not in parsed_kegg_gene_entries[i].keys():\n",
    "        pass\n",
    "    elif parsed_kegg_gene_entries[i]['BRITE']['BRITE_PATHS'] == []:\n",
    "        pass\n",
    "    else:\n",
    "        name = parsed_kegg_gene_entries[i]['BRITE']['BRITE_PATHS'][0][-1]\n",
    "        if name in find_names:\n",
    "            lookup_dict[name] = i\n",
    "lookup_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2afc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if permuting gene identities\n",
    "# torch.manual_seed(5461)\n",
    "\n",
    "# keys = [e for e in lookup_dict.keys()]\n",
    "\n",
    "# # vals = [lookup_dict[e] for e in lookup_dict.keys()]\n",
    "# # dict(zip(keys, [int(i) for i in torch.randperm(len(keys))]))\n",
    "\n",
    "# idx = torch.tensor([lookup_dict[e] for e in myvnn.nodes_inp])\n",
    "# idx = idx[torch.randperm(idx.shape[0])]\n",
    "# idx = [int(i) for i in idx]\n",
    "# temp = dict(zip(myvnn.nodes_inp, idx))\n",
    "\n",
    "# randomized_lookup_dict = {}\n",
    "# for e in lookup_dict.keys():\n",
    "#     if e not in temp.keys():\n",
    "#         randomized_lookup_dict[e] = lookup_dict[e]\n",
    "#     else:\n",
    "#         randomized_lookup_dict[e] = temp[e]\n",
    "\n",
    "# lookup_dict = randomized_lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brite_node_to_list_idx_dict = {}\n",
    "for i in range(len(kegg_gene_brite)):\n",
    "    brite_node_to_list_idx_dict[str(kegg_gene_brite[i]['BRITE']['BRITE_PATHS'][0][-1])] = i        \n",
    "\n",
    "# Get the input sizes for the graph\n",
    "size_in_zip = zip(myvnn.nodes_inp, [np.prod(ACGT_gene_slice_list[lookup_dict[e]].shape[1:]) for e  in myvnn.nodes_inp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# init input node sizes\n",
    "myvnn.set_node_props(key = 'inp', node_val_zip = size_in_zip)\n",
    "\n",
    "# init node output sizes\n",
    "myvnn.set_node_props(key = 'out', node_val_zip = zip(myvnn.nodes_inp, [default_out_nodes_inp  for e in myvnn.nodes_inp]))\n",
    "myvnn.set_node_props(key = 'out', node_val_zip = zip(myvnn.nodes_edge,[default_out_nodes_edge for e in myvnn.nodes_edge]))\n",
    "myvnn.set_node_props(key = 'out', node_val_zip = zip(myvnn.nodes_out, [default_out_nodes_out  for e in myvnn.nodes_out]))\n",
    "\n",
    "\n",
    "# # options should be controlled by node_props\n",
    "myvnn.set_node_props(key = 'flatten', node_val_zip = zip(\n",
    "    myvnn.nodes_inp, \n",
    "    [True for e in myvnn.nodes_inp]))\n",
    "\n",
    "myvnn.set_node_props(key = 'reps', node_val_zip = zip(myvnn.nodes_inp, [default_reps_nodes_inp  for e in myvnn.nodes_inp]))\n",
    "myvnn.set_node_props(key = 'reps', node_val_zip = zip(myvnn.nodes_edge,[default_reps_nodes_edge for e in myvnn.nodes_edge]))\n",
    "myvnn.set_node_props(key = 'reps', node_val_zip = zip(myvnn.nodes_out, [default_reps_nodes_out  for e in myvnn.nodes_out]))\n",
    "\n",
    "myvnn.set_node_props(key = 'drop', node_val_zip = zip(myvnn.nodes_inp, [default_drop_nodes_inp  for e in myvnn.nodes_inp]))\n",
    "myvnn.set_node_props(key = 'drop', node_val_zip = zip(myvnn.nodes_edge,[default_drop_nodes_edge for e in myvnn.nodes_edge]))\n",
    "myvnn.set_node_props(key = 'drop', node_val_zip = zip(myvnn.nodes_out, [default_drop_nodes_out  for e in myvnn.nodes_out]))\n",
    "\n",
    "# init edge node input size (propagate forward input/edge outpus)\n",
    "myvnn.calc_edge_inp()\n",
    "\n",
    "# myvnn.mk_digraph(include = ['node_name', 'inp_size', 'out_size'])\n",
    "# myvnn.mk_digraph(include = [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnvDL.dlfn import plDNN_general, BigDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742569ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = X.get('KEGG_slices', ops_string='asarray from_numpy float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to the tensors that will be used\n",
    "vals = [vals[lookup_dict[i]] for i in myvnn.nodes_inp] #TODO CONFIRM.\n",
    "# send to gpu\n",
    "# vals = [val.to('cuda') for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace lookup so that it matches the lenght of the input tensors\n",
    "new_lookup_dict = {}\n",
    "for i in range(len(myvnn.nodes_inp)):\n",
    "    new_lookup_dict[myvnn.nodes_inp[i]] = i\n",
    "    # print((myvnn.nodes_inp[i], i))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## start insert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c8d1c",
   "metadata": {},
   "source": [
    "### Calculate nodes membership in each matrix and positions within each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1434feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myvnn.nodes_inp\n",
    "# vals[new_lookup_dict['100282167']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_props = myvnn.node_props\n",
    "# Linear_block = Linear_block_reps,\n",
    "edge_dict = myvnn.edge_dict\n",
    "dependancy_order = myvnn.dependancy_order\n",
    "node_to_inp_num_dict = new_lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b506f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dep order\n",
    "\n",
    "tally = []\n",
    "for d in dependancy_order:\n",
    "    if edge_dict[d] == []:\n",
    "        tally.append(d)\n",
    "    elif False not in [True if e in tally else False for e in edge_dict[d]]:\n",
    "        tally.append(d)\n",
    "    else:\n",
    "        print('error!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build output nodes \n",
    "d_out = {0:[]}\n",
    "for d in dependancy_order:\n",
    "    if edge_dict[d] == []:\n",
    "        d_out[min(d_out.keys())].append(d)\n",
    "    else:\n",
    "        # print((d, edge_dict[d]))\n",
    "\n",
    "        d_out_i = 1+max(sum([[key for key in d_out.keys() if e in d_out[key]]\n",
    "                   for e in edge_dict[d]], []))\n",
    "        \n",
    "        if d_out_i not in d_out.keys():\n",
    "            d_out[d_out_i] = []\n",
    "        d_out[d_out_i].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee02f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build input nodes NOPE. THE PASSHTROUGHS! \n",
    "d_eye = {}\n",
    "tally = []\n",
    "for i in range(max(d_out.keys()), min(d_out.keys()), -1):\n",
    "    # print(i)\n",
    "    nodes_needed = sum([edge_dict[e] for e in d_out[i]], [])+tally\n",
    "    # check against what is there and then dedupe\n",
    "    nodes_needed = [e for e in nodes_needed if e not in d_out[i-1]]\n",
    "    nodes_needed = list(set(nodes_needed))\n",
    "    tally = nodes_needed\n",
    "    d_eye[i] = nodes_needed\n",
    "\n",
    "# d_inp[0]= d_out[0]\n",
    "    \n",
    "[len(d_eye[i]) for i in d_eye.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b883050",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, len(d_out[key])) for key in d_out.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40581c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {}\n",
    "for i in d_eye.keys():\n",
    "    dd[i] = {'out': d_out[i],\n",
    "             'inp': d_out[i-1],\n",
    "             'eye': d_eye[i]}\n",
    "# plus special 0 layer that handles the snps\n",
    "    \n",
    "dd[0] = {'out': d_out[0],\n",
    "         'inp': d_out[0],\n",
    "         'eye': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the output nodes' inputs are satisfied by the same layer's inputs (inp and eye)\n",
    "\n",
    "for i in dd.keys():\n",
    "    # out node in each\n",
    "    for e in dd[i]['out']:\n",
    "        # node depends in inp/eye\n",
    "        node_pass_list = [True if ee in dd[i]['inp']+dd[i]['eye'] else False \n",
    "                          for ee in edge_dict[e]]\n",
    "        if False not in node_pass_list:\n",
    "            pass\n",
    "        else:\n",
    "            print('exit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Layer\\t#In\\t#Out\")\n",
    "for i in range(min(dd.keys()), max(dd.keys())+1, 1):\n",
    "    node_in      = [node_props[e]['out'] for e in dd[i]['inp']+dd[i  ]['eye'] ]\n",
    "    if i == max(dd.keys()):\n",
    "        node_out = [node_props[e]['out'] for e in dd[i]['out'] ]\n",
    "    else:\n",
    "        node_out = [node_props[e]['out'] for e in dd[i]['out']+dd[i+1]['eye']]\n",
    "    print(f'{i}:\\t{sum(node_in)}\\t{sum(node_out)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c249b2f",
   "metadata": {},
   "source": [
    "### Creating Structured Matrices for Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31998d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86792df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class structured_layer_info:\n",
    "    def __init__(self, i, \n",
    "                 dd,  # {1: {'out': ['OtherTubulinModificationProteins',\n",
    "                      #      'inp': [\n",
    "                      #      'eye': [\n",
    "                 node_props, # {'KeggOrthology(Ko)[Br-Zma00001]': {'out': 1, 'reps': 1, 'drop': 0.0, 'inp': 7},\n",
    "                 edge_dict,\n",
    "                 as_sparse = False\n",
    "                 ):\n",
    "        self.row_inp = dd[i]['inp']\n",
    "        self.row_eye = dd[i]['eye']\n",
    "\n",
    "        self.col_out = dd[i]['out']\n",
    "        self.col_eye = []\n",
    "        if i+1 in dd.keys():\n",
    "            self.col_eye = dd[i+1]['eye'] \n",
    "\n",
    "        # build lookup dicts of the information on each side\n",
    "        row_nodes = [e for e in self.row_inp+self.row_eye]\n",
    "        col_nodes = [e for e in self.col_out+self.col_eye]\n",
    "\n",
    "        if i == min(dd.keys()):\n",
    "            # print('check')\n",
    "            row_sizes = [node_props[e]['inp'] for e in row_nodes]\n",
    "        else:\n",
    "            row_sizes = [node_props[e]['out'] for e in row_nodes]\n",
    "        col_sizes = [node_props[e]['out'] for e in col_nodes]\n",
    "\n",
    "        row_sizes = torch.Tensor(row_sizes).to(torch.int)\n",
    "        row_stop  = torch.cumsum(row_sizes, 0)\n",
    "        row_start = torch.concat([torch.Tensor([0]).to(torch.int), row_stop[0:-1]])\n",
    "\n",
    "        col_sizes = torch.Tensor(col_sizes).to(torch.int)\n",
    "        col_stop  = torch.cumsum(col_sizes, 0)\n",
    "        col_start = torch.concat([torch.Tensor([0]).to(torch.int), col_stop[0:-1]])\n",
    "\n",
    "        self.row_info = {}\n",
    "        for j in range(len(row_sizes)):\n",
    "            self.row_info[row_nodes[j]]= {\n",
    "                # 'row_nodes': row_nodes[j],\n",
    "                'size': row_sizes[j],\n",
    "                     'stop':  row_stop[j],\n",
    "                    'start': row_start[j],\n",
    "            }\n",
    "\n",
    "        self.col_info = {}\n",
    "        for j in range(len(col_sizes)):\n",
    "            self.col_info[col_nodes[j]]= {\n",
    "                # 'col_nodes': col_nodes[j],\n",
    "                'size': col_sizes[j],\n",
    "                     'stop':  col_stop[j],\n",
    "                    'start': col_start[j],\n",
    "            }\n",
    "    \n",
    "        ## Init weight & bias matrix ====\n",
    "        self.weight          = torch.zeros([row_stop[-1], col_stop[-1]])\n",
    "        self.weight_bool     = torch.zeros([row_stop[-1], col_stop[-1]]) # 1 if is weight\n",
    "        self.weight_eye_bool = torch.zeros([row_stop[-1], col_stop[-1]]) # 1 if is eye\n",
    "        self.bias            = torch.zeros([              col_stop[-1]])\n",
    "        self.bias_eye_bool   = torch.zeros([              col_stop[-1]]) # 1 if is eye\n",
    "\n",
    "        for e in self.col_out:\n",
    "            c_size = self.col_info[e]['size']\n",
    "            # print(f'i {i} key min {min(dd.keys())}')\n",
    "            if i == min(dd.keys()):\n",
    "                inps = [e]\n",
    "            else:\n",
    "                inps = edge_dict[e]\n",
    "            # print(f'inps: {inps}')\n",
    "            # r_size_total = sum([self.row_info[ee]['size'] for ee in inps])\n",
    "            # W = torch.empty(r_size_total, c_size)\n",
    "            # W = torch.nn.init.kaiming_normal_(W, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "            c1 = self.col_info[e]['start']\n",
    "            c2 = self.col_info[e]['stop']\n",
    "\n",
    "            # W_start = 0\n",
    "            # print(W.shape)\n",
    "            for inp in inps:\n",
    "                r1 = self.row_info[inp]['start']\n",
    "                r2 = self.row_info[inp]['stop']\n",
    "                slice_size = r2-r1\n",
    "                # W_end = W_start + slice_size\n",
    "                # print(W_start, W_end)\n",
    "                # self.weight[r1:r2, c1:c2] = W[W_start:W_end]\n",
    "\n",
    "                # Use nn.Linear to initialize the matrix instead of doing it manually.\n",
    "                xx = nn.Linear(slice_size, c_size)\n",
    "                W = xx.weight.clone().detach().requires_grad_(False)\n",
    "                # print(f'{W.shape} {self.weight[r1:r2, c1:c2].shape}')\n",
    "                B = xx.bias.clone().detach().requires_grad_(False)\n",
    "                self.weight[r1:r2, c1:c2] = W.swapaxes(0,1)                                                          # <- transposed to match nn.Linear\n",
    "                self.weight_bool[r1:r2, c1:c2] = torch.ones(W.shape).swapaxes(0,1) # Fill in gradient bool matrix    # <- transposed to match nn.Linear\n",
    "                self.bias[c1:c2] = B\n",
    "                # W_start = W_end        \n",
    "                \n",
    "        for e in self.col_eye:\n",
    "            c_size = self.col_info[e]['size']\n",
    "            c1 = self.col_info[e]['start']\n",
    "            c2 = self.col_info[e]['stop']\n",
    "            r1 = self.row_info[e]['start']\n",
    "            r2 = self.row_info[e]['stop']\n",
    "\n",
    "            W = torch.eye(c_size)\n",
    "            self.weight[r1:r2, c1:c2] = W\n",
    "            # FIXME testing if not allowing gradients on unity entries is causing the problem. If it is then either \n",
    "            # 1. pass through gradients from one layer to the next (and or)\n",
    "            # 2. re-set these values to unity after each update. \n",
    "            self.weight_eye_bool[r1:r2, c1:c2] = torch.eye(c_size).swapaxes(0,1)                                     # <- transposed to match nn.Linear\n",
    "\n",
    "        if as_sparse:\n",
    "            self.weight      = self.weight.to_sparse()\n",
    "            self.weight_bool = self.weight_bool.to_sparse()\n",
    "            self.weight_eye_bool = self.weight_bool.to_sparse()\n",
    "            # self.bias = self.bias\n",
    "\n",
    "        ## Init identity components of matrix ====\n",
    "        # 1.0 if identity otherwise 0\n",
    "        for e in self.col_eye:\n",
    "            self.bias_eye_bool[self.col_info[e]['start']:self.col_info[e]['stop']] = 1.0\n",
    "        if self.col_eye != []:\n",
    "            self.bias_eye_bool = self.bias_eye_bool        \n",
    "\n",
    "# i = 0\n",
    "# M =structured_layer_info(i, dd, node_props, edge_dict)\n",
    "# px.imshow(M.weight.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "M =structured_layer_info(i, dd, node_props, edge_dict, as_sparse=True)\n",
    "# M.weight.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a544b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stophere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caed169",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "M =structured_layer_info(i, dd, node_props, edge_dict)\n",
    "px.imshow(M.weight.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_list = []\n",
    "# for i in range(len(M_list)):\n",
    "#     l = nn.Linear(M_list[i].weight.shape[0], M_list[i].weight.shape[1])\n",
    "#     l.weight.requires_grad = False\n",
    "#     l.weight = torch.nn.Parameter(M_list[i].weight.swapaxes(0,1))\n",
    "#     l.weight.requires_grad = True\n",
    "\n",
    "#     l.bias.requires_grad = False\n",
    "#     l.bias = torch.nn.Parameter(M_list[i].bias)\n",
    "#     l.bias.requires_grad = True\n",
    "\n",
    "#     layer_list += [l]\n",
    "    \n",
    "#     if i+1 != len(M_list):\n",
    "#         layer_list += [nn.ReLU()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2ad6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e160fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_list = [structured_layer_info(i = ii, dd = dd, node_props= node_props, edge_dict = edge_dict) for ii in range(0, max(dd.keys())+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0879ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "[e.weight.shape for e in M_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99467119",
   "metadata": {},
   "source": [
    "### Setup Dataloader using `M_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = X.get('KEGG_slices', ops_string='asarray from_numpy float')\n",
    "# restrict to the tensors that will be used\n",
    "vals = torch.concat([vals[lookup_dict[i]].reshape(4926, -1) \n",
    "                     for i in M_list[0].row_inp\n",
    "                    #  for i in dd[0]['inp'] # matches\n",
    "                     ], axis = 1)\n",
    "vals.shape\n",
    "vals = vals.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:train asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float cuda:0')[:, None],\n",
    "    # y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:test asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:val:test asarray from_numpy float cuda:0')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0011158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b255f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d1221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version to predict enviromental residuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcbd1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = '../nbs_artifacts/01.03_g2fc_prep_matrices/'\n",
    "load_from = '../nbs_artifacts/01.03_g2fc_prep_matrices/'\n",
    "phno_geno = pd.read_csv(load_from+'phno_geno.csv')\n",
    "phno = phno_geno\n",
    "\n",
    "\n",
    "obs_geno_lookup = np.load(load_from+'obs_geno_lookup.npy') # Phno_Idx  Geno_Idx  Is_Phno_Idx\n",
    "obs_env_lookup = np.load(load_from+'obs_env_lookup.npy')   # Phno_Idx  Env_Idx   Is_Phno_Idx\n",
    "YMat = np.load(load_from+'YMat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnvDL.dlfn import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create train/test validate indicies from json\n",
    "load_from = '../nbs_artifacts/01.06_g2fc_cluster_genotypes/'\n",
    "\n",
    "split_info = read_split_info(\n",
    "    load_from = '../nbs_artifacts/01.06_g2fc_cluster_genotypes/',\n",
    "    json_prefix = '2023:9:5:12:8:26')\n",
    "\n",
    "temp = phno.copy()\n",
    "temp[['Female', 'Male']] = temp['Hybrid'].str.split('/', expand = True)\n",
    "\n",
    "test_dict = find_idxs_split_dict(\n",
    "    obs_df = temp, \n",
    "    split_dict = split_info['test'][0]\n",
    ")\n",
    "# test_dict\n",
    "\n",
    "# since this is applying predefined model structure no need for validation.\n",
    "# This is included for my future reference when validation is needed.\n",
    "temp = temp.loc[test_dict['train_idx'], ] # restrict before re-aplying\n",
    "\n",
    "val_dict = find_idxs_split_dict(\n",
    "    obs_df = temp, \n",
    "    split_dict = split_info['validate'][0]\n",
    ")\n",
    "# val_dict\n",
    "\n",
    "# test_dict\n",
    "\n",
    "train_idx = test_dict['train_idx']\n",
    "test_idx  = test_dict['test_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27290fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data to get env means\n",
    "# obs_env_lookup   # Phno_Idx  Env_Idx   Is_Phno_Idx\n",
    "\n",
    "YMat_EnvMean = YMat.copy()\n",
    "\n",
    "for i in tqdm(list(set(obs_env_lookup[:, 1]))):\n",
    "    mask = (obs_env_lookup[:, 1] == i)\n",
    "    YMat_EnvMean[mask] = YMat_EnvMean[mask].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract to get residuals\n",
    "YMat = YMat - YMat_EnvMean\n",
    "# proceed as normal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "YMat_cs = calc_cs(YMat[train_idx])\n",
    "y_cs = apply_cs(YMat, YMat_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = torch.from_numpy(y_cs).to(torch.float)#[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d52ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:train asarray from_numpy'),\n",
    "    y =           y_temp[train_idx][:, None].to('cuda'),\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:test asarray from_numpy'),\n",
    "    y =           y_temp[test_idx][:, None].to('cuda'),\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e712e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:test:train asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:test:train asarray from_numpy float cuda:0')[:, None],\n",
    "    # y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = True,\n",
    "    lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "    lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:test:test asarray from_numpy'),\n",
    "    y =           X.get('YMat',            ops_string='cs filter:test:test asarray from_numpy float cuda:0')[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    # send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66553003",
   "metadata": {},
   "source": [
    "## Structured Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(M.weight.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f413908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = nn.Linear(M.weight.shape[0], M.weight.shape[1])\n",
    "\n",
    "# xx.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92065d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(xx.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx.weight = torch.nn.Parameter(M.weight.swapaxes(0,1))\n",
    "# xx.weight.requires_grad = True\n",
    "# px.imshow(xx.weight.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = []\n",
    "for i in range(len(M_list)):\n",
    "    l = nn.Linear(M_list[i].weight.shape[0], M_list[i].weight.shape[1])\n",
    "    l.weight.requires_grad = False\n",
    "    l.weight = torch.nn.Parameter(M_list[i].weight.swapaxes(0,1))\n",
    "    l.weight.requires_grad = True\n",
    "\n",
    "    l.bias.requires_grad = False\n",
    "    l.bias = torch.nn.Parameter(M_list[i].bias)\n",
    "    l.bias.requires_grad = True\n",
    "\n",
    "    layer_list += [l]\n",
    "    \n",
    "    if i+1 != len(M_list):\n",
    "        layer_list += [nn.ReLU()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13afb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa37495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = layer_list[-3]\n",
    "\n",
    "# px.imshow(l.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_sparse = SparseLinearCustom(\n",
    "#     l.in_features, \n",
    "#     l.out_features,\n",
    "#     connectivity   = torch.LongTensor(l.weight.to_sparse().indices()),\n",
    "#     custom_weights = l.weight.to_sparse().values(), \n",
    "#     custom_bias    = l.bias.clone().detach()\n",
    "#     )\n",
    "\n",
    "# px.imshow(l_sparse.weight.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert model with dense matrices to sparse matrices\n",
    "\n",
    "layer_list_new = []\n",
    "for l in layer_list:\n",
    "    if isinstance(l, nn.ReLU):\n",
    "        layer_list_new += [l]\n",
    "    if isinstance(l, nn.Linear):\n",
    "        l_sparse = SparseLinearCustom(\n",
    "            l.in_features, \n",
    "            l.out_features,\n",
    "            connectivity   = torch.LongTensor(l.weight.to_sparse().indices()),\n",
    "            custom_weights = l.weight.to_sparse().values(), \n",
    "            custom_bias    = l.bias.clone().detach()\n",
    "            )\n",
    "        layer_list_new += [l_sparse]\n",
    "\n",
    "\n",
    "del layer_list\n",
    "layer_list = layer_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(model.layer_list[-3].weight.to_dense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SparseLinearCustom(\n",
    "#     10, 10,\n",
    "#     connectivity   = torch.LongTensor(xx.to_sparse().indices()),\n",
    "#     custom_weights = xx.to_sparse().values(), \n",
    "#     custom_bias    = torch.tensor([1., 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc591510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_list):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_list = nn.ModuleList(layer_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layer_list:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313d189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(next(iter(training_dataloader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e76083",
   "metadata": {},
   "outputs": [],
   "source": [
    "VNN = plDNN_general(model)  \n",
    "\n",
    "optimizer = VNN.configure_optimizers()\n",
    "\n",
    "# logger = TensorBoardLogger(\"tb_vnn_logs\", name=save_prefix)\n",
    "# logger = TensorBoardLogger(\"tb_vnn_logs\", name='02.40_g2fc_G_ACGT_VNN_baseline_SPARSE_match_test_scale')\n",
    "logger = TensorBoardLogger(\"tb_vnn_logs\", name='02.40_g2fc_G_ACGT_VNN_baseline_SPARSE_match_net_size')\n",
    "trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "\n",
    "trainer.fit(model=VNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stophere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50541bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac098f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee550918",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_i, xs_i = next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c61393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in tqdm(range(2)):\n",
    "    pred = model(xs_i)\n",
    "    loss = loss_fn(pred, y_i)\n",
    "    if ii % 100 == 0:\n",
    "        print(f'{loss}')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training are unity weights still unity?\n",
    "i = 2\n",
    "(\n",
    "M_list[i].bias_eye_bool, \n",
    "M_list[i].weight_eye_bool,\n",
    "model.layer_list[((2*(i)))].weight,\n",
    "model.layer_list[((2*(i)))].weight.grad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.row_inp\n",
    "M.row_eye\n",
    "M.col_out\n",
    "M.col_eye\n",
    "\n",
    "M.row_info\n",
    "# M.col_info\n",
    "\n",
    "# M.weight\n",
    "# M.weight_bool\n",
    "# M.weight_eye_bool\n",
    "# M.bias\n",
    "# M.bias_eye_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = list(M_list[i].col_info.keys())[0]\n",
    "slice_accumulator = []\n",
    "# M_list[i].row_info[query]\n",
    "c1 = M_list[i].col_info[query]['start'] \n",
    "c2 = M_list[i].col_info[query]['stop']\n",
    "\n",
    "# could get full slice then drop zero values too\n",
    "for e in edge_dict[query]:\n",
    "    r1 = M_list[i].row_info[e]['start'] \n",
    "    r2 = M_list[i].row_info[e]['stop']\n",
    "    slice_accumulator += [model.layer_list[((2*(i)))].weight.swapaxes(0,1)[r1:r2, c1:c2].clone().detach().requires_grad_(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concat(slice_accumulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer_list[((2*(i)))].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89783b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8725cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35b8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_weights = {}\n",
    "for i in range(0, len(M_list)):\n",
    "    for query in M_list[i].col_out:\n",
    "        slice_accumulator = []\n",
    "        # M_list[i].row_info[query]\n",
    "        c1 = M_list[i].col_info[query]['start'] \n",
    "        c2 = M_list[i].col_info[query]['stop']\n",
    "\n",
    "        # could get full slice then drop zero values too\n",
    "        if i == 0:\n",
    "            r1 = M_list[i].row_info[query]['start'] \n",
    "            r2 = M_list[i].row_info[query]['stop']\n",
    "            slice_accumulator += [model.layer_list[((2*(i)))].weight.swapaxes(0,1)[r1:r2, c1:c2].clone().detach().requires_grad_(False)]\n",
    "\n",
    "        else: \n",
    "            for e in edge_dict[query]:\n",
    "                r1 = M_list[i].row_info[e]['start'] \n",
    "                r2 = M_list[i].row_info[e]['stop']\n",
    "                slice_accumulator += [model.layer_list[((2*(i)))].weight.swapaxes(0,1)[r1:r2, c1:c2].clone().detach().requires_grad_(False)]\n",
    "\n",
    "        slice_accumulator = torch.concat(slice_accumulator)\n",
    "        node_to_weights[query] = slice_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b078d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b35dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = [np.round(float(node_to_weights[key].abs().mean()), 3) for key in node_to_weights.keys()]\n",
    "color_vals = ['#ffffff', '#fff7ec', '#fee8c8', '#fdd49e', '#fdbb84', '#fc8d59', '#ef6548', '#d7301f', '#b30000'#, '#7f0000'\n",
    "              ]\n",
    "color_cutoffs = [i*max(xx)/len(color_vals) for i in range(len(color_vals))]\n",
    "\n",
    "\n",
    "dot = Digraph()\n",
    "for key in node_to_weights.keys():\n",
    "\n",
    "\n",
    "    key_mean_w = np.round(float(node_to_weights[key].abs().mean()), 3)\n",
    "    color_val = color_vals[[i for i in range(len(color_cutoffs)) if key_mean_w >= color_cutoffs[i]][-1]]\n",
    "\n",
    "    # key_label = name_cleanup(input = key, newline_char_threshold = 20)+'\\nMean: '+str(key_mean_w)\n",
    "    # dot.node(key, key_label, style='filled', fillcolor=color_val)  \n",
    "    \n",
    "    \n",
    "    key_label = name_cleanup(input = key, newline_char_threshold = 20)+'\\n           '  \n",
    "    dot.node(key, key_label)\n",
    "\n",
    "    if key in kegg_connections.keys():\n",
    "        for value in kegg_connections[key]:\n",
    "            # edge takes a head/tail whereas edges takes name pairs concatednated (A, B -> AB)in a list\n",
    "            dot.edge(value, key)    \n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## end insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VisableNeuralNetwork(\n",
    "#     node_props = myvnn.node_props,\n",
    "#     Linear_block = Linear_block_reps,\n",
    "#     edge_dict = myvnn.edge_dict,\n",
    "#     dependancy_order = myvnn.dependancy_order,\n",
    "#     node_to_inp_num_dict = new_lookup_dict\n",
    "# )\n",
    "# model = model.to('cuda')\n",
    "# # # with torch.no_grad(): print(model(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d26433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if randomizing y\n",
    "# torch.manual_seed(2608434)\n",
    "\n",
    "# y_trn = X.get('YMat', ops_string='cs filter:val:train asarray from_numpy float')\n",
    "# y_trn = y_trn[torch.randperm(y_trn.shape[0])]\n",
    "\n",
    "\n",
    "# y_val = X.get('YMat', ops_string='cs filter:val:train asarray from_numpy float')\n",
    "# y_val = y_val[torch.randperm(y_val.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training_dataloader = DataLoader(BigDataset(\n",
    "#     lookups_are_filtered = True,\n",
    "#     lookup_obs =  X.get('val:train',       ops_string='                   asarray from_numpy'), \n",
    "#     lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:train asarray from_numpy'),\n",
    "#     y =           X.get('YMat',            ops_string='cs filter:val:train asarray from_numpy float cuda:0')[:, None],\n",
    "#     G =           vals,\n",
    "#     G_type = 'list',\n",
    "#     # send_batch_to_gpu = 'cuda:0'\n",
    "#     ),\n",
    "#     batch_size = batch_size,\n",
    "#     shuffle = True\n",
    "# )\n",
    "\n",
    "# validation_dataloader = DataLoader(BigDataset(\n",
    "#     lookups_are_filtered = True,\n",
    "#     lookup_obs =  X.get('val:test',        ops_string='                   asarray from_numpy'), \n",
    "#     lookup_geno = X.get('obs_geno_lookup', ops_string='   filter:val:test asarray from_numpy'),\n",
    "#     y =           X.get('YMat',            ops_string='cs filter:val:test asarray from_numpy float cuda:0')[:, None],\n",
    "#     G =           vals,\n",
    "#     G_type = 'list',\n",
    "#     # send_batch_to_gpu = 'cuda:0'\n",
    "#     ),\n",
    "#     batch_size = batch_size,\n",
    "#     shuffle = False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98873813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSUV_(model, data = next(iter(training_dataloader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VNN = plDNN_general(model)  \n",
    "\n",
    "# optimizer = VNN.configure_optimizers()\n",
    "\n",
    "# logger = TensorBoardLogger(\"tb_vnn_logs\", name=save_prefix)\n",
    "# trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "\n",
    "# trainer.fit(model=VNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f695e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time, json\n",
    "# save_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "# json_path = cache_path+''.join(['lookup_dict','__'+save_time,'.json'])\n",
    "# with open(json_path, 'w', encoding='utf-8') as f: \n",
    "#     json.dump(new_lookup_dict, f, ensure_ascii=False, indent=4)    \n",
    "\n",
    "# pt_path = cache_path+''.join([save_prefix,'__'+save_time,'.pt'])\n",
    "\n",
    "# torch.save(VNN.mod, pt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

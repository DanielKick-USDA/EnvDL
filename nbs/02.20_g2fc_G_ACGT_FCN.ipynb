{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aadccc0",
   "metadata": {},
   "source": [
    "# G only ACGT Probabilities\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "import hilbertcurve\n",
    "from hilbertcurve.hilbertcurve import HilbertCurve\n",
    "\n",
    "from EnvDL.core import * # includes remove_matching_files\n",
    "from EnvDL.dna  import *\n",
    "from EnvDL.dlfn import * # includes LSUV_\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcbcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_gpu_num = 0\n",
    "\n",
    "# Imports --------------------------------------------------------------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F # F.mse_loss\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if use_gpu_num in [0, 1]: \n",
    "    torch.cuda.set_device(use_gpu_num)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../nbs_artifacts/02.20_g2fc_G_ACGT_FCN/'\n",
    "ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5b870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05162f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277b7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, re, json\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# import plotly.express as px\n",
    "# import plotly.io as pio\n",
    "# pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch import nn\n",
    "\n",
    "# from EnvDL.core import * \n",
    "# # includes \n",
    "#     # remove_matching_files \n",
    "#     # read_json\n",
    "# from EnvDL.dna import *\n",
    "# from EnvDL.dlfn import * \n",
    "# # includes\n",
    "#     # read_split_info \n",
    "#     # find_idxs_split_dict\n",
    "#     # train_loop_yx\n",
    "#     # train_error_yx\n",
    "#     # test_loop_yx\n",
    "#     # train_nn_yx\n",
    "#     # yhat_loop_yx\n",
    "\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb11c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_gpu_num = 0\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# if use_gpu_num in [0, 1]: \n",
    "#     torch.cuda.set_device(use_gpu_num)\n",
    "# print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66364b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports for the Adaptive Experimentation (Ax) platform\n",
    "# from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "# from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "# from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "# import pickle as pkl\n",
    "# # Because the search space is nested, it's not storable with the builtin methods for saving/reading json (not tested with sql)\n",
    "# # pickling seems to work just fine.\n",
    "\n",
    "# init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4600ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_path = '../nbs_artifacts/02.20_g2fc_G_ACGT_FCN/'\n",
    "# ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517af1f8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e59a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = '../nbs_artifacts/01.03_g2fc_prep_matrices/'\n",
    "phno_geno = pd.read_csv(load_from+'phno_geno.csv')\n",
    "phno = phno_geno\n",
    "\n",
    "obs_geno_lookup = np.load(load_from+'obs_geno_lookup.npy') # Phno_Idx\tGeno_Idx\tIs_Phno_Idx\n",
    "YMat = np.load(load_from+'YMat.npy')\n",
    "ACGT = np.load(load_from+'ACGT.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913dec1",
   "metadata": {},
   "source": [
    "### Create train/test validate indicies from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = '../nbs_artifacts/01.06_g2fc_cluster_genotypes/'\n",
    "\n",
    "split_info = read_split_info(\n",
    "    load_from = '../nbs_artifacts/01.06_g2fc_cluster_genotypes/',\n",
    "    json_prefix = '2023:9:5:12:8:26')\n",
    "\n",
    "temp = phno.copy()\n",
    "temp[['Female', 'Male']] = temp['Hybrid'].str.split('/', expand = True)\n",
    "\n",
    "test_dict = find_idxs_split_dict(\n",
    "    obs_df = temp, \n",
    "    split_dict = split_info['test'][0]\n",
    ")\n",
    "\n",
    "temp = temp.loc[test_dict['train_idx'], ] # restrict before re-aplying\n",
    "\n",
    "val_dict = find_idxs_split_dict(\n",
    "    obs_df = temp, \n",
    "    split_dict = split_info['validate'][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3824096",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = val_dict['train_idx']\n",
    "test_idx  = val_dict['test_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85db139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all observation idxs are have genomic information\n",
    "assert [] == [e for e in list(train_idx)+list(test_idx) if e not in obs_geno_lookup[:, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02205e69",
   "metadata": {},
   "source": [
    "## One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaedf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all observation idxs are have genomic information\n",
    "# assert [] == [e for e in list(train_idx)+list(test_idx) if e not in obs_geno_lookup[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02004189",
   "metadata": {},
   "outputs": [],
   "source": [
    "YMat_cs = calc_cs(YMat[train_idx])\n",
    "y_cs = apply_cs(YMat, YMat_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d63ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Data -----------------------------------------------------------------------------------\n",
    "\n",
    "train_idx = val_dict['train_idx']\n",
    "test_idx  = val_dict['test_idx']\n",
    "\n",
    "training_dataloader = DataLoader(\n",
    "    ACGTDataset(y = torch.from_numpy(y_cs[train_idx])[:, None].to(torch.float), \n",
    "                G = torch.from_numpy(ACGT).to(torch.float), \n",
    "                idx_original = torch.from_numpy(np.array(train_idx)),\n",
    "                idx_lookup   = torch.from_numpy(np.asarray(obs_geno_lookup)),\n",
    "                use_gpu_num = 0,\n",
    "                device = 'cuda'\n",
    "               ),\n",
    "    batch_size = 50,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    ACGTDataset(y = torch.from_numpy(y_cs[test_idx])[:, None].to(torch.float), \n",
    "                G = torch.from_numpy(ACGT).to(torch.float), \n",
    "                idx_original = torch.from_numpy(np.array(test_idx)),\n",
    "                idx_lookup   = torch.from_numpy(np.asarray(obs_geno_lookup)),\n",
    "                use_gpu_num = 0,\n",
    "                device = 'cuda'\n",
    "               ),\n",
    "    batch_size = 50,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30973ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45742e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quirk of this is that to get only a single layer the length of the input tensor must be passed in. for 2+ I'll figure it out.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, parameterization):\n",
    "        super(NeuralNetwork, self).__init__()            \n",
    "        module_list = []\n",
    "\n",
    "        max_layer = parameterization['num_layers']\n",
    "        for i in range(max_layer):\n",
    "            if i  == 0:\n",
    "                name_in = f\"in_{i+1}_of_{max_layer}\"\n",
    "            else:\n",
    "                name_in = f\"out_{i}_of_{max_layer}\"\n",
    "            name_out = f\"out_{i+1}_of_{max_layer}\"\n",
    "            name_drop= f\"drop_{i+1}_of_{max_layer}\"\n",
    "\n",
    "            if i == 0:\n",
    "                module_list += [nn.Flatten()]\n",
    "            \n",
    "\n",
    "            module_list += [\n",
    "                Linear_block(\n",
    "                    in_size  = parameterization[name_in], \n",
    "                    out_size = parameterization[name_out], \n",
    "                    drop_pr  = parameterization[name_drop])]\n",
    "            \n",
    "            if (i+1) == max_layer:\n",
    "                module_list += [nn.Linear(parameterization[name_out], 1)]\n",
    "                \n",
    "        self.x_network = nn.ModuleList(module_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for mod in self.x_network:\n",
    "            if mod == self.x_network[-1]:\n",
    "                out = x # get the penultimate layer's outputs for later\n",
    "            x = mod(x)\n",
    "        \n",
    "        pred = x\n",
    "        return pred, out\n",
    "\n",
    "# model = NeuralNetwork(\n",
    "#     parameterization = parameterization).to(device)\n",
    "\n",
    "# model(next(iter(training_dataloader))[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfea7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bad64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenince wrapper to fill in for R's seq or x:y notation\n",
    "def linrange(start, stop):\n",
    "    import numpy as np\n",
    "    diff = start - stop\n",
    "    res = np.linspace(start, stop, abs(diff)+1).astype(int)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b27a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # [2048, 1024, 512, 256, 128, 64, 32, 16]\n",
    "layer_sizes = [int(2**i) for i in linrange(start = 11, stop = 4)]\n",
    "layer_drops = [0.1 for e in layer_sizes]\n",
    "\n",
    "num_layers = len(layer_sizes)\n",
    "\n",
    "params = {\n",
    "    'num_layers':num_layers,\n",
    "    f\"in_1_of_{num_layers}\": (ACGT.shape[1] * ACGT.shape[2])\n",
    "}\n",
    "\n",
    "for i in range(num_layers):\n",
    "    params[f\"out_{ i + 1}_of_{num_layers}\"] = layer_sizes[i]\n",
    "    params[f\"drop_{ i + 1}_of_{num_layers}\"] = layer_drops[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(parameterization = params).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0012af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0c4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying orthogonal init (zero init if dim < 2) to params in 9 module(s).\n",
      "Applying LSUV to 9 module(s) (up to 10 iters per module):\n",
      "Module  0 after  2 itr(s) | Mean:  0.041 | Std: 1.000 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  1 after  2 itr(s) | Mean: -0.049 | Std: 0.994 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  2 after  2 itr(s) | Mean:  0.044 | Std: 0.999 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  3 after  2 itr(s) | Mean:  0.020 | Std: 1.002 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  4 after  2 itr(s) | Mean:  0.032 | Std: 1.038 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  5 after  2 itr(s) | Mean: -0.114 | Std: 0.998 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  6 after  2 itr(s) | Mean: -0.113 | Std: 0.992 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  7 after  2 itr(s) | Mean: -0.203 | Std: 0.951 | <class 'torch.nn.modules.linear.Linear'>\n",
      "Module  8 after  2 itr(s) | Mean: -0.444 | Std: 0.954 | <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "LSUV_(model, data = next(iter(training_dataloader))[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(next(iter(training_dataloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module for training subnetworks.\n",
    "class plDNN_ACGT(pl.LightningModule):\n",
    "    def __init__(self, mod):\n",
    "        super().__init__()\n",
    "        self.mod = mod\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        g_i, y_i = batch\n",
    "        pred, out = self.mod(g_i)\n",
    "        loss = F.mse_loss(pred, y_i)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            weight_list=[(name, param) for name, param in model.named_parameters() if name.split('.')[-1] == 'weight']\n",
    "            for l in weight_list:\n",
    "                self.log((\"train_mean\"+l[0]), l[1].mean())\n",
    "                self.log((\"train_std\"+l[0]), l[1].std())        \n",
    "        return(loss)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        g_i, y_i = batch\n",
    "        pred, out = self.mod(g_i)\n",
    "        loss = F.mse_loss(pred, y_i)\n",
    "        self.log('val_loss', loss)        \n",
    "     \n",
    "    def configure_optimizers(self, **kwargs):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), **kwargs)\n",
    "        return optimizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: tb_logs/g-acgt-fcn\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 1.0 B \n",
      "---------------------------------------\n",
      "1.0 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 B     Total params\n",
      "4,136.397 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc92b512b9b94fb694ecd8495dc86293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epoch = 100\n",
    "DNNG = plDNN_ACGT(model)     \n",
    "optimizer = DNNG.configure_optimizers()\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"g-acgt-fcn\")\n",
    "trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "\n",
    "trainer.fit(model=DNNG, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(DNNG.mod, cache_path+'g-acgt-fcn'+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078ced1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ca007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACGTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c67cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66573ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DNNCO_G(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DNNCO_G, self).__init__()    \n",
    "        \n",
    "#         self.g_network =nn.Sequential(\n",
    "#             Linear_block(in_size= 4881, out_size= 83, drop_pr= 0.163923177),\n",
    "#             Linear_block(in_size= 83,   out_size= 133, drop_pr= 0.230663142)\n",
    "#         ) \n",
    "#         self.g_pred =nn.Sequential(\n",
    "#             nn.Linear(133, 1)\n",
    "#         ) \n",
    "                \n",
    "#     def forward(self, tensor_list):\n",
    "#         y, g, s, w = tensor_list\n",
    "#         g_out = self.g_network(g)\n",
    "#         g_pred = self.g_pred(g_out)\n",
    "#         return g_pred, g_out\n",
    "    \n",
    "# DNNCO_G().to(device)(next(iter(training_dataloader)) )[0].shape\n",
    "\n",
    "# model = DNNCO_G().to(device)\n",
    "# LSUV_(model, data = next(iter(training_dataloader)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97711cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Module for training subnetworks.\n",
    "# class plDNNCO_subnet(pl.LightningModule):\n",
    "#     def __init__(self, mod):\n",
    "#         super().__init__()\n",
    "#         self.mod = mod\n",
    "        \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         # train loop\n",
    "# #         y_i, g_i, s_i, w_i = batch\n",
    "# #         pred, out = self.mod(g_i, s_i, w_i)\n",
    "#         y_i, _, _, _ = batch\n",
    "#         pred, out = self.mod(batch)\n",
    "#         # print(y_i.shape, pred.shape)\n",
    "#         loss = F.mse_loss(pred, y_i)\n",
    "#         self.log(\"train_loss\", loss)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             weight_list=[(name, param) for name, param in model.named_parameters() if name.split('.')[-1] == 'weight']\n",
    "#             for l in weight_list:\n",
    "#                 self.log((\"train_mean\"+l[0]), l[1].mean())\n",
    "#                 self.log((\"train_std\"+l[0]), l[1].std())        \n",
    "#         return(loss)\n",
    "        \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "# #         y_i, g_i, s_i, w_i = batch\n",
    "# #         pred, out = self.mod(g_i, s_i, w_i)\n",
    "#         y_i, _, _, _ = batch\n",
    "#         pred, out = self.mod(batch)\n",
    "#         # print(y_i.shape, pred.shape)\n",
    "#         loss = F.mse_loss(pred, y_i)\n",
    "#         self.log('val_loss', loss)        \n",
    "     \n",
    "#     def configure_optimizers(self, **kwargs):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), **kwargs)\n",
    "#         return optimizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc63c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa375c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e8b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f562d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570ac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1062e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb28cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60381c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29805d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f8e8f7",
   "metadata": {},
   "source": [
    "## Tune with `ax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be able to take a dictionary with the parameters that can be varied.\n",
    "\n",
    "# must subclass train_nn to make changes to the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0ab35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ee531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8825a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = [i for i in np.linspace(1, 32, 10)]\n",
    "# ys = [round(e**2) for e in xs]\n",
    "# px.scatter(\n",
    "#     pd.DataFrame({'x': xs, 'y': ys}),\n",
    "#     x ='x', y= 'y')\n",
    "\n",
    "# [int(2**i) for i in np.linspace(1, 10, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c73a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_layer_blocks = [1]+[2*(1+i) for i in range(6)]\n",
    "# in_size_int = 4*125891\n",
    "# out_size_choice = [2**(4+i) for i in range(7)] #16 <-> 1024\n",
    "# drop_pr_choice = [(5*e)/100 for e in range(11)] # 0 <-> 50\n",
    "# epoch_choice = [2, 1024]\n",
    "\n",
    "# # See https://github.com/facebook/Ax/issues/1454#issuecomment-1462417398\n",
    "\n",
    "# # num_layer_blocks = [1, 2]\n",
    "# # in_size_int\n",
    "# # out_size_choice = [16, 32]\n",
    "# # drop_pr_choice = [0.0, 0.3]\n",
    "# # epoch_choice\n",
    "\n",
    "# params = [\n",
    "#     {\n",
    "#         \"name\": \"num_layers\",\n",
    "#         \"type\": \"choice\",\n",
    "#         \"is_ordered\": True, \n",
    "#         \"values\": num_layer_blocks,\n",
    "#         \"dependents\": {\n",
    "#             num_layers: [\n",
    "#                 f\"in_{  i + 1}_of_{num_layers}\" for i in range(num_layers) if i == 0]+[\n",
    "#                 f\"out_{ i + 1}_of_{num_layers}\" for i in range(num_layers)]+[\n",
    "#                 f\"drop_{i + 1}_of_{num_layers}\" for i in range(num_layers)]+[\n",
    "#                 f\"epoch_of_{num_layers}\" for i in range(num_layers) if i == 0\n",
    "#             ] for num_layers in num_layer_blocks\n",
    "#         }\n",
    "#     },\n",
    "#     *[  # * here puts the entries of the list comprehension into the outer list instead of keeping them as a sub-list\n",
    "#         {\n",
    "#             \"name\": f\"in_{ i + 1}_of_{num_layers}\",\n",
    "#             \"type\": \"fixed\",\n",
    "#             \"value_type\": 'int',\n",
    "#             \"value\": in_size_int\n",
    "#         } for num_layers in num_layer_blocks for i in range(num_layers) if i == 0\n",
    "        \n",
    "#     ],\n",
    "#     *[\n",
    "#         {\n",
    "#             \"name\": f\"out_{ i + 1}_of_{num_layers}\",\n",
    "#             \"type\": \"choice\",\n",
    "#             \"is_ordered\": True, \n",
    "#             \"value_type\": 'int',\n",
    "#             \"values\": out_size_choice\n",
    "#         } for num_layers in num_layer_blocks for i in range(num_layers) \n",
    "        \n",
    "#     ],\n",
    "#     *[\n",
    "#         {\n",
    "#             \"name\": f\"drop_{ i + 1}_of_{num_layers}\",\n",
    "#             \"type\": \"choice\",\n",
    "#             \"is_ordered\": True, \n",
    "#             \"value_type\": 'float',\n",
    "#             \"values\": drop_pr_choice\n",
    "#         } for num_layers in num_layer_blocks for i in range(num_layers) \n",
    "        \n",
    "#     ],\n",
    "#     *[\n",
    "#         {\n",
    "#             \"name\": f\"epoch_of_{num_layers}\",\n",
    "#             \"type\": \"range\",\n",
    "# #             \"is_ordered\": True, \n",
    "#             \"value_type\": 'int',\n",
    "#             \"bounds\": epoch_choice\n",
    "#         } for num_layers in num_layer_blocks \n",
    "        \n",
    "#     ],\n",
    "    \n",
    "# ]\n",
    "# # params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53962c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize\n",
    "# ax_client = AxClient()\n",
    "\n",
    "# # Using SAASBO per https://github.com/facebook/Ax/issues/1454#issuecomment-1462417398\n",
    "# # Create an experiment with required arguments: name, parameters, and objective_name.\n",
    "# ax_client.create_experiment(\n",
    "#     name=\"tune_fcn_layer_number\",  # The name of the experiment.\n",
    "#     parameters=params,\n",
    "#     objectives={\"rmse\": ObjectiveProperties(minimize=True)},  # The objective name and minimization setting.\n",
    "#     # parameter_constraints: Optional, a list of strings of form \"p1 >= p2\" or \"p1 + p2 <= some_bound\".\n",
    "#     # outcome_constraints: Optional, a list of strings of form \"constrained_metric <= some_bound\".\n",
    "#     choose_generation_strategy_kwargs={\"use_saasbo\": True}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if there already is a set of test results, then load it.\n",
    "# if os.path.exists(cache_path+'ax_client.pkl'):\n",
    "#     ax_client = None\n",
    "#     with open(cache_path+'ax_client.pkl', 'rb') as f:\n",
    "#         dat = pkl.load(f)\n",
    "#     ax_client = dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7184894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self, parameterization):\n",
    "#         super(NeuralNetwork, self).__init__()    \n",
    "\n",
    "#         def Linear_block(in_size, out_size, drop_pr):\n",
    "#             block = nn.Sequential(\n",
    "#                 nn.Linear(in_size, out_size),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(drop_pr)\n",
    "#             )\n",
    "#             return(block)         \n",
    "        \n",
    "#         module_list = []\n",
    "\n",
    "#         max_layer = parameterization['num_layers']\n",
    "#         for i in range(max_layer):\n",
    "#             if i  == 0:\n",
    "#                 name_in = f\"in_{i+1}_of_{max_layer}\"\n",
    "#             else:\n",
    "#                 name_in = f\"out_{i}_of_{max_layer}\"\n",
    "#             name_out = f\"out_{i+1}_of_{max_layer}\"\n",
    "#             name_drop= f\"drop_{i+1}_of_{max_layer}\"\n",
    "\n",
    "#             if i == 0:\n",
    "#                 module_list += [nn.Flatten()]\n",
    "\n",
    "#             module_list += [\n",
    "#                     Linear_block(\n",
    "#                         in_size  = parameterization[name_in], \n",
    "#                         out_size = parameterization[name_out], \n",
    "#                         drop_pr  = parameterization[name_drop])]\n",
    "\n",
    "#             if (i+1) == max_layer:\n",
    "#                 module_list += [nn.Linear(parameterization[name_out], 1)]\n",
    "                \n",
    "#         self.x_network = nn.ModuleList(module_list)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         for mod in self.x_network:\n",
    "#             x = mod(x)\n",
    "            \n",
    "#         return x\n",
    "\n",
    "# # model = NeuralNetwork(\n",
    "# #     parameterization = parameterization).to(device)\n",
    "\n",
    "# # model(next(iter(training_dataloader))[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ffbd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameters and run the trial \n",
    "# baseline_parameters = ax_client.get_trial_parameters(trial_index=0)\n",
    "# ax_client.complete_trial(trial_index=0, raw_data=train_evaluate(baseline_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_evaluate(parameterization, use_validation_sets = 1):\n",
    "#     dataloader_batch_size = 50\n",
    "#     # run_epochs = 2\n",
    "\n",
    "#     loss_list = []    \n",
    "#     for validate_i in list(np.random.choice(\n",
    "#         [i for i in range(len(split_info['validate']))], \n",
    "#         use_validation_sets, \n",
    "#         replace = False)):\n",
    "#         print(f\"Running with validation set: {validate_i}\")\n",
    "\n",
    "#         val_dict = find_idxs_split_dict(\n",
    "#             obs_df = obs_df_ref, \n",
    "#             split_dict = split_info['validate'][validate_i]\n",
    "#         )\n",
    "\n",
    "#         train_idx = val_dict['train_idx']\n",
    "#         test_idx  = val_dict['test_idx']\n",
    "\n",
    "#         training_dataloader = DataLoader(\n",
    "#             ACGTDataset(y = torch.from_numpy(y_cs[train_idx])[:, None].to(torch.float), \n",
    "#                         G = torch.from_numpy(ACGT).to(torch.float), \n",
    "#                         idx_original = torch.from_numpy(np.array(train_idx)),\n",
    "#                         idx_lookup   = torch.from_numpy(np.asarray(obs_geno_lookup)),\n",
    "#                         use_gpu_num = 0,\n",
    "#                         device = 'cuda'\n",
    "#                        ),\n",
    "#             batch_size = 50,\n",
    "#             shuffle = True\n",
    "#         )\n",
    "\n",
    "#         testing_dataloader = DataLoader(\n",
    "#             ACGTDataset(y = torch.from_numpy(y_cs[test_idx])[:, None].to(torch.float), \n",
    "#                         G = torch.from_numpy(ACGT).to(torch.float), \n",
    "#                         idx_original = torch.from_numpy(np.array(test_idx)),\n",
    "#                         idx_lookup   = torch.from_numpy(np.asarray(obs_geno_lookup)),\n",
    "#                         use_gpu_num = 0,\n",
    "#                         device = 'cuda'\n",
    "#                        ),\n",
    "#             batch_size = 50,\n",
    "#             shuffle = True\n",
    "#         )\n",
    "\n",
    "#         model = NeuralNetwork(parameterization = parameterization)    \n",
    "#         model.to(device)    \n",
    "#         model, loss_df = train_nn(\n",
    "#             cache_path,\n",
    "#             training_dataloader,\n",
    "#             testing_dataloader,\n",
    "#             model,\n",
    "#             learning_rate = 1e-3,\n",
    "#             batch_size = dataloader_batch_size,\n",
    "#             epochs = parameterization[f\"epoch_of_{parameterization['num_layers']}\"]\n",
    "#         )\n",
    "#         loss_list += [list(loss_df['TestMSE'])[-1]]\n",
    "    \n",
    "#     mean_loss = (sum(loss_list)/len(loss_list))\n",
    "#     print((mean_loss, loss_list))\n",
    "#     return(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_evaluate(parameterization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211afc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     parameters, trial_index = ax_client.get_next_trial()\n",
    "#     # Local evaluation here can be replaced with deployment to external system.\n",
    "#     ax_client.complete_trial(trial_index=trial_index, \n",
    "#                              raw_data=train_evaluate(parameters))\n",
    "    \n",
    "#     # Ax has built in functions to save client state to JSON or to a database. The builtins \n",
    "#     # (save_to_json_file, load_from_json_file) fail, seemingly from having a nested search space. \n",
    "#     # No debugging information found on Stackoverflow or google so I'm using this work around. \n",
    "#     # Warning on running ax_client.complete_trial\n",
    "#     #     UserWarning:\n",
    "#     # Cannot flatten observation features ObservationFeatures(parameters={}, trial_index=0) as full parameterization is not recorded in metadata.\n",
    "    \n",
    "#     with open(cache_path+'ax_client.pkl', 'wb') as f:\n",
    "#         pkl.dump(ax_client, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax_client.get_trials_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_parameters, values = ax_client.get_best_parameters()\n",
    "# best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, covariance = values\n",
    "# mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1201e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render(ax_client.get_contour_plot(param_x=\"drop_1_of_2\", \n",
    "#                                   param_y=\"drop_2_of_2\", \n",
    "#                                   metric_name=\"rmse\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43e309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e4a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax_client.save_to_json_file(filepath = cache_path+'ax_client.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6df9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restored_ax_client = (\n",
    "#     AxClient.load_from_json_file(filepath = cache_path+'ax_client.json') \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55902e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f46546",
   "metadata": {},
   "source": [
    "## Train Finalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6704c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_batch_size = 50\n",
    "# run_epochs = 2#100\n",
    "\n",
    "# # don't run if either of these exist because there may be cases where we want the results but not the model\n",
    "# import re\n",
    "\n",
    "# if not os.path.exists(cache_path+'/model.pt'): \n",
    "#     # Shared setup (train from scratch and load latest)\n",
    "#     model = NeuralNetwork()\n",
    "\n",
    "#     # find the biggest model to save\n",
    "#     saved_models = os.listdir(cache_path)\n",
    "#     saved_models = [e for e in saved_models if re.match('model*', e)]\n",
    "\n",
    "#     if saved_models == []:\n",
    "#         epochs_run = 0\n",
    "#     else:\n",
    "#         saved_models = [e for e in saved_models if e != 'model.pt']\n",
    "#         # if there are saved models reload and resume training\n",
    "#         saved_models_numbers = [int(e.replace('model_', ''\n",
    "#                                     ).replace('.pt', ''\n",
    "#                                     ).split('_')[0]) for e in saved_models]\n",
    "#         # saved_models\n",
    "#         epochs_run = max(saved_models_numbers)+1 # add 1 to account for 0 index\n",
    "#         latest_model = [e for e in saved_models if re.match(\n",
    "#             '^model_'+str(epochs_run-1)+'_.*\\.pt$', e)][0] # subtract 1 to convert back\n",
    "#         model.load_state_dict(torch.load(cache_path+latest_model))\n",
    "#         print('Resuming Training: '+str(epochs_run)+'/'+str(run_epochs)+' epochs run.')\n",
    "    \n",
    "#     model.to(device)    \n",
    "\n",
    "#     model, loss_df = train_nn(\n",
    "#         cache_path,\n",
    "#         training_dataloader,\n",
    "#         testing_dataloader,\n",
    "#         model,\n",
    "#         learning_rate = 1e-3,\n",
    "#         batch_size = dataloader_batch_size,\n",
    "#         epochs = (run_epochs - epochs_run)\n",
    "#     )\n",
    "    \n",
    "#     # experimental outputs:\n",
    "#     # 1. Model\n",
    "#     torch.save(model.state_dict(), cache_path+'/model.pt') # convention is to use .pt or .pth\n",
    "\n",
    "#     # 2. loss_df    \n",
    "#     # If this is resuming training, load and extend the existing loss dataframe\n",
    "#     if os.path.exists(cache_path+'/loss_df.csv'):\n",
    "#         loss_df_on_disk = pd.read_csv(cache_path+'/loss_df.csv')\n",
    "#         epoch_offset = 1 + loss_df_on_disk['Epoch'].max()\n",
    "#         loss_df['Epoch'] = loss_df['Epoch'] + epoch_offset\n",
    "#         loss_df = pd.concat([loss_df_on_disk, loss_df])\n",
    "#     loss_df.to_csv(cache_path+'/loss_df.csv', index=False)  \n",
    "    \n",
    "#     # 3. predictions \n",
    "#     yhats = pd.concat([\n",
    "#         yhat_loop(testing_dataloader, model).assign(Split = 'Test'),\n",
    "#         yhat_loop(training_dataloader, model).assign(Split = 'Train')], axis = 0)\n",
    "\n",
    "#     yhats.to_csv(cache_path+'/yhats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a4976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4764b227",
   "metadata": {},
   "source": [
    "### Standard Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddb930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be3103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0001b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad680db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_dict = {'y1':YMat_cs}\n",
    "# import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naieve_yhat = training_dataloader.dataset.y.mean()\n",
    "\n",
    "# naieve_MSE_Train = reverse_cs( \n",
    "#     np.array(((naieve_yhat - training_dataloader.dataset.y)**2)).mean(),\n",
    "#     scale_dict['y1']\n",
    "# )\n",
    "\n",
    "# naieve_MSE_Test = reverse_cs( \n",
    "#     np.array(((naieve_yhat - testing_dataloader.dataset.y)**2)).mean(),\n",
    "#     scale_dict['y1']\n",
    "# )\n",
    "\n",
    "# naieve_MSE_Train, naieve_MSE_Test\n",
    "\n",
    "\n",
    "\n",
    "# loss_df = pd.read_csv(cache_path+'/loss_df.csv')\n",
    "\n",
    "# loss_df.TrainMSE = reverse_cs(loss_df.TrainMSE, scale_dict['y1'])\n",
    "# loss_df.TestMSE  = reverse_cs(loss_df.TestMSE , scale_dict['y1'])\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=loss_df.Epoch, y=loss_df.TestMSE,\n",
    "#                     mode='lines', name='Test'))\n",
    "# fig.add_trace(go.Scatter(x=loss_df.Epoch, y=loss_df.TrainMSE,\n",
    "#                     mode='lines', name='Train'))\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=loss_df.Epoch, y=[naieve_MSE_Test  for e in range(len(loss_df.Epoch))], \n",
    "#                          mode='lines', name='Naieve Test'))\n",
    "# fig.add_trace(go.Scatter(x=loss_df.Epoch, y=[naieve_MSE_Train for e in range(len(loss_df.Epoch))], \n",
    "#                          mode='lines', name='Naieve Train'))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b66997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhats = pd.read_csv(cache_path+'/yhats.csv')\n",
    "\n",
    "# # px.scatter(yhats, x = 'y_true', y = 'y_pred', color = 'Split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhats.y_true = reverse_cs(yhats.y_true, scale_dict['y1'])\n",
    "# yhats.y_pred = reverse_cs(yhats.y_pred, scale_dict['y1'])\n",
    "\n",
    "# # px.scatter(yhats, x = 'y_true', y = 'y_pred', color = 'Split', trendline=\"ols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhats['Error'] = yhats.y_pred - yhats.y_true\n",
    "\n",
    "# px.histogram(yhats, x = 'Error', color = 'Split',\n",
    "#              marginal=\"box\", # can be `rug`, `violin`\n",
    "#              nbins= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

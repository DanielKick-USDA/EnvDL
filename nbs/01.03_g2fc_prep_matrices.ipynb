{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn import preprocessing # LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error # if squared=False; RMSE\n",
    "\n",
    "from EnvDL.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../nbs_artifacts/01.03_g2fc_prep_matrices/'\n",
    "ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = '../nbs_artifacts/01.02_g2fc_imputation/'\n",
    "\n",
    "meta = pd.read_csv(load_from+'meta0.csv')\n",
    "# meta['Date_Planted'] = meta['Date_Planted'].astype(int)\n",
    "# meta['Date_Harvested'] = meta['Date_Harvested'].astype(int)\n",
    "phno = pd.read_csv(load_from+'phno0.csv')\n",
    "soil = pd.read_csv(load_from+'soil0.csv')\n",
    "wthr = pd.read_csv(load_from+'wthr0.csv')\n",
    "# wthrWide = pd.read_csv(load_from+'wthrWide0.csv')\n",
    "cgmv = pd.read_csv(load_from+'cgmv0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087d405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((phno.Yield_Mg_ha.notna())) # This used to allow for missing yield so long as they were in \n",
    "# 2022. Now that the 2022 data is available they should be excluded.\n",
    "phno = phno.loc[mask, :].reset_index().drop(columns = 'index')\n",
    "phno = phno.loc[:, ['Env', 'Year', 'Hybrid', 'Yield_Mg_ha']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec008a",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5b519",
   "metadata": {},
   "source": [
    "## Prep CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YMat[phno.Year == 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f443f0",
   "metadata": {},
   "source": [
    "## Prep y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "YMat = np.array(phno.Yield_Mg_ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99012086",
   "metadata": {},
   "source": [
    "## One Hot Encode G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = phno.loc[:, ['Env', 'Year', 'Hybrid', 'Yield_Mg_ha']]\n",
    "temp = pd.concat([temp, temp.Hybrid.str.split('/', expand=True)], axis=1\n",
    "        ).rename(columns = {0:'P0', 1:'P1'})\n",
    "temp\n",
    "uniq_parents = list(set(pd.concat([temp['P0'], temp['P1']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abandoned grouping so that 'PHN11_PHW65_0107' and 'PHN11_PHW65_0260' are the same\n",
    "\n",
    "# search_str = 'PHN11_PHW65'\n",
    "# search_list = ['PH207_PHG47-17',\n",
    "#  '4N506',\n",
    "#  'BGEM-0157-N',\n",
    "#  'PHN11_PHW65_0107',\n",
    "#  'W10004_0013',\n",
    "#  'PHW65_MOG_0106',\n",
    "#  'PHN11_PHW65_0260',\n",
    "#  'PHN11_PHW65_0276',\n",
    "#  'MOG',\n",
    "#  'PHN11_PHW65-0514',\n",
    "#  'MO44_PHW65_0475']\n",
    "\n",
    "\n",
    "# res_list = [e for e in search_list if re.match(search_str+'[-|_]\\d+', e)]\n",
    "\n",
    "# print(search_str, ':', res_list, ',')\n",
    "\n",
    "# # uniq_parents = [e for e in uniq_parents if e not in res_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5252b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GMat = np.zeros([temp.shape[0], len(uniq_parents)])\n",
    "\n",
    "for j in tqdm.tqdm(range(len(uniq_parents))):\n",
    "    for parent in ['P0', 'P1']:\n",
    "        mask = (temp[parent] == uniq_parents[j]) \n",
    "        GMat[temp.loc[mask, ].index, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97622023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm there are two parents encoded for each observation\n",
    "assert 2 == np.min(np.sum(GMat, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd878c",
   "metadata": {},
   "source": [
    "## Make S Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMat = phno.loc[:, ['Env']].merge(soil.drop(columns = ['Unnamed: 0', 'Year'])).drop(columns = ['Env'])\n",
    "SMatNames = list(SMat)\n",
    "SMat = np.array(SMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168fe87",
   "metadata": {},
   "source": [
    "## Prep W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dae4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (N,Cin,Lin)(N,Cin,Lin) or (Cin,Lin)(Cin,Lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WMatNames = list(wthr.drop(columns = ['Unnamed: 0', 'Env', 'Year', 'Date', 'DOY']))\n",
    "WMat = np.zeros([   # Pytorch uses\n",
    "    phno.shape[0],  # N\n",
    "    len(WMatNames), # Cin\n",
    "    np.max(wthr.DOY)# Lin\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa41a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135793/135793 [00:03<00:00, 37137.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all obs, but only add each env once (add to all relevant obs)\n",
    "added_envs = []\n",
    "for i in tqdm.tqdm(phno.index):\n",
    "    env = phno.loc[i, 'Env']\n",
    "\n",
    "    if env in added_envs:\n",
    "        pass\n",
    "    else:\n",
    "        mask = (phno.Env == env)\n",
    "        WMat_idxs = phno.loc[mask, ].index\n",
    "\n",
    "        # selected data is transposed to match correct shape\n",
    "        wthr_mask = (wthr.Env == env)\n",
    "        WMat[WMat_idxs, :, :] = wthr.loc[wthr_mask, \n",
    "                                   ].sort_values('DOY'\n",
    "                                   ).drop(columns = ['Unnamed: 0', 'Env', \n",
    "                                                     'Year', 'Date', 'DOY']).T\n",
    "\n",
    "        added_envs += [env]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f0094",
   "metadata": {},
   "source": [
    "## Prep CGMV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430668e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMatNames = list(cgmv.drop(columns = ['Unnamed: 0', 'Env', 'Year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMat = np.zeros([   \n",
    "    phno.shape[0],  \n",
    "    len(MMatNames)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7273cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135793/135793 [00:02<00:00, 65836.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all obs, but only add each env once (add to all relevant obs)\n",
    "added_envs = []\n",
    "for i in tqdm.tqdm(phno.index):\n",
    "    env = phno.loc[i, 'Env']\n",
    "\n",
    "    if env in added_envs:\n",
    "        pass\n",
    "    else:\n",
    "        mask = (phno.Env == env)\n",
    "        MMat_idxs = phno.loc[mask, ].index\n",
    "\n",
    "        # selected data is transposed to match correct shape\n",
    "        cgmv_mask = (cgmv.Env == env)\n",
    "        MMat[MMat_idxs, :] = cgmv.loc[cgmv_mask, \n",
    "                                ].drop(columns = ['Unnamed: 0', 'Env', 'Year'])\n",
    "\n",
    "        added_envs += [env]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3405c8",
   "metadata": {},
   "source": [
    "# Save data\n",
    "This will streamline model generation. I'll just need to load these files in and can directly begin modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7defc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(cache_path+'GMatNames.npy', uniq_parents)\n",
    "np.save(cache_path+'SMatNames.npy', SMatNames)\n",
    "np.save(cache_path+'WMatNames.npy', WMatNames)\n",
    "np.save(cache_path+'MMatNames.npy', MMatNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8588fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phno.to_csv(cache_path+'phno3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(cache_path+'YMat3.npy', YMat)\n",
    "np.save(cache_path+'GMat3.npy', GMat)\n",
    "np.save(cache_path+'SMat3.npy', SMat)\n",
    "np.save(cache_path+'WMat3.npy', WMat)\n",
    "np.save(cache_path+'MMat3.npy', MMat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

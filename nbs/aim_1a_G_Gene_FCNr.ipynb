{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# Fully Connected Genomic Model (Only Geneic SNPs) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from   torch import nn\n",
    "import torch.nn.functional as F\n",
    "from   torch.utils.data import Dataset\n",
    "from   torch.utils.data import DataLoader\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from   lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from dataG2F.core import get_data\n",
    "from dataG2F.qol  import ensure_dir_path_exists\n",
    "\n",
    "from EnvDL.dlfn import BigDataset, plDNN_general\n",
    "from EnvDL.sets import mask_parents # for creating sets on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnvDL.dlfn import Linear_res_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../nbs_artifacts/aim_1a_G_Gene_FCNr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings: \n",
    "params_run = {\n",
    "    'batch_size': 256,\n",
    "    'max_epoch' : 64,   \n",
    "}\n",
    "\n",
    "# data settings\n",
    "params_data = {\n",
    "    'y_var': 'Yield_Mg_ha',\n",
    "    'y_resid': 'None', # None, Env, Geno\n",
    "    'y_resid_strat': 'None', # None, naive_mean, filter_mean, ...\n",
    "    'holdout_parents': [\n",
    "        ## 2022 ====\n",
    "        'LH244',\n",
    "        ## 2021 ====\n",
    "        'PHZ51',\n",
    "        # 'PHP02',\n",
    "        # 'PHK76',\n",
    "        ## 2019 ====\n",
    "        # 'PHT69',\n",
    "        'LH195',\n",
    "        ## 2017 ====\n",
    "        # 'PHW52',\n",
    "        # 'PHN82',\n",
    "        ## 2016 ====\n",
    "        # 'DK3IIH6',\n",
    "        ## 2015 ====\n",
    "        # 'PHB47',\n",
    "        # 'LH82',\n",
    "        ## 2014 ====\n",
    "        # 'LH198',\n",
    "        # 'LH185',\n",
    "        # 'PB80',\n",
    "        # 'CG102',\n",
    " ],    \n",
    "}\n",
    "\n",
    "# in this file I define params later. I've included it here to gurantee that we can merge other params dicts into it.\n",
    "params = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = params_run['batch_size']\n",
    "max_epoch  = params_run['max_epoch']\n",
    "\n",
    "y_var = params_data['y_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_prefix = [e for e in cache_path.split('/') if e != ''][-1]\n",
    "\n",
    "if 'None' != params_data['y_resid_strat']:\n",
    "    save_prefix = save_prefix+'_'+params_data['y_resid_strat']\n",
    "\n",
    "ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_gpu_num = 0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if use_gpu_num in [0, 1]: \n",
    "    torch.cuda.set_device(use_gpu_num)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_geno_lookup          = get_data('obs_geno_lookup')\n",
    "phno                     = get_data('phno')\n",
    "acgt                     = get_data('KEGG_slices')\n",
    "acgt                     = np.concatenate(acgt, axis= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten data\n",
    "acgt = acgt.reshape(4926, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make holdout sets\n",
    "holdout_parents = params_data['holdout_parents']\n",
    "\n",
    "# create a mask for parent genotype\n",
    "mask = mask_parents(df= phno, col_name= 'Hybrid', holdout_parents= holdout_parents)\n",
    "\n",
    "train_mask = mask.sum(axis=1) == 0\n",
    "test_mask  = mask.sum(axis=1) > 0\n",
    "\n",
    "train_idx = train_mask.loc[train_mask].index\n",
    "test_idx  = test_mask.loc[test_mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y to residual if needed\n",
    "\n",
    "if params_data['y_resid'] == 'None':\n",
    "    pass\n",
    "else:\n",
    "    if params_data['y_resid_strat'] == 'naive_mean':\n",
    "        # use only data in the training set (especially since testers will be more likely to be found across envs)\n",
    "        # get enviromental means, subtract from observed value\n",
    "        tmp = phno.loc[train_idx, ]\n",
    "        env_mean = tmp.groupby(['Env_Idx']\n",
    "                     ).agg(Env_Mean = (y_var, 'mean')\n",
    "                     ).reset_index()\n",
    "        tmp = phno.merge(env_mean)\n",
    "        tmp.loc[:, y_var] = tmp.loc[:, y_var] - tmp.loc[:, 'Env_Mean']\n",
    "        phno = tmp.drop(columns='Env_Mean')\n",
    "\n",
    "    if params_data['y_resid_strat'] == 'filter_mean':\n",
    "        # for adjusting to environment we could use _all_ observations but ideally we will use the same set of genotypes across all observations\n",
    "        def minimum_hybrids_for_env(tmp = phno.loc[:, ['Env', 'Year', 'Hybrid']],\n",
    "                                    year = 2014):\n",
    "            # Within each year what hybrids are most common?\n",
    "            tmp = tmp.loc[(tmp.Year == year), ].groupby(['Env', 'Hybrid']).count().reset_index().sort_values('Year')\n",
    "\n",
    "            all_envs = set(tmp.Env)\n",
    "            # if we filter on the number of sites a hybrid is planted at, what is the largest number of sites we can ask for before we lose a location?\n",
    "            # site counts for sets which contain all envs\n",
    "            i = max([i for i in list(set(tmp.Year)) if len(set(tmp.loc[(tmp.Year >= i), 'Env'])) == len(all_envs)])\n",
    "\n",
    "            before = len(set(tmp.loc[:, 'Hybrid']))\n",
    "            after  = len(set(tmp.loc[(tmp.Year >= i), 'Hybrid']))\n",
    "            print(f'Reducing {year} hybrids from {before} to {after} ({round(100*after/before)}%).')\n",
    "            tmp = tmp.loc[(tmp.Year >= i), ['Env', 'Hybrid']].reset_index(drop=True)\n",
    "            return tmp\n",
    "\n",
    "\n",
    "        tmp = phno.loc[:, ['Env', 'Year', 'Hybrid']]\n",
    "        filter_hybrids = [minimum_hybrids_for_env(tmp = phno.loc[:, ['Env', 'Year', 'Hybrid']], year = i) \n",
    "                          for i in list(set(phno.Year)) ]\n",
    "        env_mean = pd.concat(filter_hybrids).merge(phno, how = 'left')\n",
    "\n",
    "        env_mean = env_mean.groupby(['Env_Idx']\n",
    "                          ).agg(Env_Mean = (y_var, 'mean')\n",
    "                          ).reset_index()\n",
    "\n",
    "        tmp = phno.merge(env_mean)\n",
    "        tmp.loc[:, y_var] = tmp.loc[:, y_var] - tmp.loc[:, 'Env_Mean']\n",
    "        phno = tmp.drop(columns='Env_Mean')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and y value data\n",
    "assert 0 == phno.loc[:, y_var].isna().sum()\n",
    "\n",
    "y = phno.loc[:, y_var]\n",
    "# use train index to prevent information leakage\n",
    "y_c = y[train_idx].mean()\n",
    "y_s = y[train_idx].std()\n",
    "\n",
    "y = (y - y_c)/y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = False,\n",
    "    lookup_obs  = torch.from_numpy(np.array(train_idx)), \n",
    "    lookup_geno = torch.from_numpy(obs_geno_lookup),\n",
    "    y =           torch.from_numpy(y.to_numpy()).to(torch.float32)[:, None],\n",
    "    G =           torch.from_numpy(acgt).to(torch.float32),\n",
    "    G_type = 'raw',\n",
    "    send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = False,\n",
    "    lookup_obs  = torch.from_numpy(np.array(test_idx)), \n",
    "    lookup_geno = torch.from_numpy(obs_geno_lookup),\n",
    "    y =           torch.from_numpy(y.to_numpy()).to(torch.float32)[:, None],\n",
    "    G =           torch.from_numpy(acgt).to(torch.float32),\n",
    "    G_type = 'raw',\n",
    "    send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenince wrapper to fill in for R's seq or x:y notation\n",
    "def linrange(start, stop):\n",
    "    import numpy as np\n",
    "    diff = start - stop\n",
    "    res = np.linspace(start, stop, abs(diff)+1).astype(int)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2048, 1024, 512, 256, 128, 64, 32, 16]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2**i for i in linrange(11, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is designed to go from (3x125891) -> ~1258.91  -> ~125.891 -> ~12.5891 -> 1\n",
    "layer_sizes = [1024, 128, 12]\n",
    "layer_drops = [0.1 for e in layer_sizes]\n",
    "\n",
    "num_layers = len(layer_sizes)\n",
    "\n",
    "params = {\n",
    "    'num_layers':num_layers,\n",
    "    f\"in_1_of_{num_layers}\": (4 * 75419)\n",
    "}\n",
    "\n",
    "for i in range(num_layers):\n",
    "    params[f\"out_{ i + 1}_of_{num_layers}\"] = layer_sizes[i]\n",
    "    params[f\"drop_{ i + 1}_of_{num_layers}\"] = layer_drops[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 3,\n",
       " 'in_1_of_3': 301676,\n",
       " 'out_1_of_3': 1024,\n",
       " 'drop_1_of_3': 0.1,\n",
       " 'out_2_of_3': 128,\n",
       " 'drop_2_of_3': 0.1,\n",
       " 'out_3_of_3': 12,\n",
       " 'drop_3_of_3': 0.1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([256, 1]), torch.Size([256, 301676])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.shape for e in next(iter(training_dataloader))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quirk of this is that to get only a single layer the length of the input tensor must be passed in. for 2+ I'll figure it out.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, parameterization):\n",
    "        super(NeuralNetwork, self).__init__()            \n",
    "        module_list = []\n",
    "\n",
    "        max_layer = parameterization['num_layers']\n",
    "        for i in range(max_layer):\n",
    "            if i  == 0:\n",
    "                name_in = f\"in_{i+1}_of_{max_layer}\"\n",
    "            else:\n",
    "                name_in = f\"out_{i}_of_{max_layer}\"\n",
    "            name_out = f\"out_{i+1}_of_{max_layer}\"\n",
    "            name_drop= f\"drop_{i+1}_of_{max_layer}\"\n",
    "\n",
    "            if i == 0:\n",
    "                module_list += [nn.Flatten()]\n",
    "            \n",
    "\n",
    "            module_list += [\n",
    "                Linear_res_block(\n",
    "                    in_size  = parameterization[name_in], \n",
    "                    out_size = parameterization[name_out], \n",
    "                    drop_pr  = parameterization[name_drop])]\n",
    "            \n",
    "            if (i+1) == max_layer:\n",
    "                module_list += [nn.Linear(parameterization[name_out], 1)]\n",
    "                \n",
    "        self.x_network = nn.ModuleList(module_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for mod in self.x_network:\n",
    "            if mod == self.x_network[-1]:\n",
    "                out = x # get the penultimate layer's outputs for later\n",
    "            x = mod(x)\n",
    "        \n",
    "        pred = x\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(parameterization = params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(next(iter(training_dataloader))[1])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 311 M \n",
      "---------------------------------------\n",
      "311 M     Trainable params\n",
      "0         Non-trainable params\n",
      "311 M     Total params\n",
      "1,244.730 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f2873ae3434eea994cc42ff33498b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c6c3469f54c10b7b4d107e822da0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1ae0cf0b58414e97ecc2a67cc19650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eed8e426f84448b3793addac7c1fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a9425cfb6e4cc2b2257c3d6a4bcafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05005979c794bce933e69b7878b3c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbc5903c35f430cb4c169c860f4510c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765157daf99e47e287539e285ab4f5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bf2c7fa1a946128148ce193dab5e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2a2e30c3e34214994b9bd5a3428dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa42b71a94514739bb873d25f3e955ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b4a66ba02c48ee94bfe6f42e431d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6716a873d51d4ad5b48198f8846dfc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9743a642d8254ad39bfb419c0773fd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5db73f27d04fb9bf2ceb7faff52e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1754e955af644c4a58b45349c9b8104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7145237c5941559c0a7ad12cebf31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9883d0be9f424c1faf433fc2ef38702e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbe4959068d4fe4819fa391cde8392e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92745915052949c1bff2fb1489b0ab55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad2859017aa4b51976c2478636cb287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6208a12c9e64f6b9fca5a6f17571c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ead7419f777435987b5d081d6deffb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486c15c0ce5f4c529109529ce3b6fa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff242af1db7468eb804a6bc6871bc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9ecd4e06474d9fb0411acdde17df3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ab5b8d08d74e08abdfb6672a9c0145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbb20eb596246f784618f5ea8c4d551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0847d844ef034e7eb326032e63199636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f4cd8e9aaa42a5949a03092b75dce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aef44bf5a064e68995937486b8add84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfa47503860448a8971f253260f1082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c5b8e8c79f4585806f4c046da1cb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d39e585653342598455157289651b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caa255d9a7641d49cd44581dca97115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3eab8ec4ca49c2a721d7e550f73c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b03eea348874ae9b5d359976a9e04c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab8049b186543329f5e0b7b72c519c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c6e42482c1492e982309b99158cfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed74976cb1645c4b38b0f69d9872ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f2acaa2bfa4539acde980673e53777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4387c4918154941bf12962146198237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4403d3fb2a274c1fa5c13d5ddd3bd5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e382ae6ffa841faaae256eb05c99e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292b654d1b844ff9bea67eb8c2c3d408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bb51a2525e4967b906067af84127a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d001fe7b0f643c79271180d9724e27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389d0cf927ef47c89e6f2d94d1724ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc334c8c4c1c405d97da435a78ec00d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d876198050043a2b59fab23a1e2e6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e7700000924880b0e844853cf3f18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00876628ecbe4759bb13072e1312c44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224e73a37e544717988305e5744d739c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7985905bc3425285184fdb7d5061cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e11fbba3d624c1d9eeb80166b35485c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eebc08c9c44e9ebb90fd1b941db25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232bb482b4db490bbe99461697df7b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb252acd529c4a6ebbd3bff0d0fc7aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645dc2e103174955bca9531f81c4d5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484508d79dd64f189ac6bb6cc102781d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dd317d72f449d48163637f75b4ac52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f745ddf57069467c906f3fb7ee29348a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98e0f29bc1249a9bf7900a1d3c493d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c80f36ba91c4414932f070225695e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542c0f99709e486db936b466786305af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0dfb7fc9144b5c9ecdf9336a19b883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=64` reached.\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "DNN = plDNN_general(model)  \n",
    "\n",
    "optimizer = DNN.configure_optimizers()\n",
    "\n",
    "logger = CSVLogger(\"nifa_tb\", name=save_prefix)\n",
    "logger.log_hyperparams(params={\n",
    "    'params': params,\n",
    "    'params_data': params_data,\n",
    "    'params_run' : params_run,\n",
    "    'misc': {\n",
    "        'n_train': len(train_idx),\n",
    "        'n_test':  len(test_idx)\n",
    "    }\n",
    "})\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "\n",
    "trainer.fit(model=DNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with versioning. \n",
    "# this is hacky but should work\n",
    "import os\n",
    "versions = os.listdir('nifa_tb/'+save_prefix)\n",
    "versions.sort()\n",
    "torch.save(DNN.mod, cache_path+versions[-1]+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

---
title: 'Create Benchmark Models:'
jupyter: python3
---


> 


```{python}
import os

import numpy as np
import pandas as pd
pd.set_option('display.max_columns', None)

import plotly.express as px

import hilbertcurve
from hilbertcurve.hilbertcurve import HilbertCurve

from EnvDL.core import * # includes remove_matching_files
# from EnvDL.dna import *
# from EnvDL.dlfn import *

from tqdm import tqdm
```

```{python}
from sklearn.metrics import mean_squared_error # if squared=False; RMSE
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

import optuna

from joblib import Parallel, delayed # Oputna has parallelism built in but for training replicates of the selected model
# I'll run them through Parallel
```

```{python}
cache_path = '../nbs_artifacts/01.80_g2fc_ML_benchrmark/'
ensure_dir_path_exists(dir_path = cache_path)
```

## Load data

```{python}
# load_from = '../nbs_artifacts/01.03_g2fc_prep_matrices/'
# # phno = pd.read_csv(load_from+'phno.csv')
# phno_geno = pd.read_csv(load_from+'phno_geno_filter.csv')
# phno = phno_geno

# obs_geno_lookup = np.load(load_from+'obs_geno_lookup.npy') # Phno_Idx	Geno_Idx	Is_Phno_Idx
# YMat = np.load(load_from+'YMat.npy')
# GMat = np.load(load_from+'GMat.npy')
# # ACGT_OneHot = np.load(load_from+'ACGT_OneHot.npy')
# # ACGT = np.load(load_from+'ACGT.npy')
# # ACGT_hilb = np.load(load_from+'ACGT_hilb.npy')
# SMat = np.load(load_from+'SMat.npy')
# WMat = np.load(load_from+'WMat.npy')
# MMat = np.load(load_from+'MMat.npy')
```

```{python}
# GMatNames = np.load(load_from+'GMatNames.npy')
# SMatNames = np.load(load_from+'SMatNames.npy')
# WMatNames = np.load(load_from+'WMatNames.npy')
# MMatNames = np.load(load_from+'MMatNames.npy')
```

## SKlearn modeling

```{python}
# # transform to panel data
# def wthr_rank_3to2(x_3d):
#     n_obs, n_days, n_metrics = x_3d.shape
#     return(x_3d.reshape(n_obs, (n_days*n_metrics)))

# def wthr_features_rank_2to3(x_3d, feature_import):
#     n_obs, n_days, n_metrics = x_3d.shape
#     return(feature_import.reshape(n_days, n_metrics))

# def y_rank_2to1(y_2d):
#     n_obs = y_2d.shape[0]
#     return(y_2d.reshape(n_obs, ))
```

```{python}
# Placeholder training/testing setup
```

```{python}
# GMat.shape
```

```{python}
# may need to expand matrices for sklearn... 
```

```{python}
# YMat.shape
```

```{python}
# obs_geno_lookup.shape
```

```{python}
# okay_phno_idx = obs_geno_lookup[:, 0]
# np.random.shuffle(okay_phno_idx)
# test_idx  = okay_phno_idx[0:1000]
# train_idx = okay_phno_idx[1000:-1]
```

```{python}
# obs_geno_lookup
```

```{python}
# regr = RandomForestRegressor(max_depth= 16, 
#                              random_state=0,
#                              n_estimators = 20)

#                                  # phno indexes
#                                  # |          geno indexes
# rf = regr.fit(GMat[obs_geno_lookup[train_idx, 1], :], # inflate deduplicated GMat to match what sklearn expects.
#               YMat[train_idx])
```

```{python}
# print([
#         mean_squared_error(YMat[train_idx], rf.predict(GMat[obs_geno_lookup[train_idx, 1], :]), squared=False), 
#         mean_squared_error(YMat[test_idx],  rf.predict(GMat[obs_geno_lookup[test_idx, 1], :]), squared=False)
#     ])
```


```{python}
# yhats = pd.concat([
#     pd.DataFrame(zip(YMat[test_idx],
#                  rf.predict(GMat[obs_geno_lookup[test_idx, 1], :])), 
#                  columns = ['y_true', 'y_pred']).assign(Split = 'Test'),
#     pd.DataFrame(zip(YMat[train_idx],
#                  rf.predict(GMat[obs_geno_lookup[train_idx, 1], :])), 
#                  columns = ['y_true', 'y_pred']).assign(Split = 'Train')
# ])

# # px.scatter(yhats, x = 'y_true', y = 'y_pred', color = 'Split', trendline="ols")
```


```{python}
# px.bar(pd.DataFrame(dict(cols=GMatNames, imp=rf.feature_importances_)), x = 'cols', y = 'imp')
```

```{python}
#  yhats['Error'] = yhats.y_pred - yhats.y_true

# px.histogram(yhats, x = 'Error', color = 'Split',
#              marginal="box", # can be `rug`, `violin`
#              nbins= 50)
```

